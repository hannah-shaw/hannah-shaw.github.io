[{"title":"SAILER：面向法律案例检索的结构感知预训练语言模型","path":"/2024/04/19/SAILER：面向法律案例检索的结构感知预训练语言模型/","content":"SAILER：面向法律案例检索的结构感知预训练语言模型SAILER: Structure-awarePre-trained Language Model for Legal Case Retrieval Author: Tsinghua UniversityType: Academic JournalPublisher: SIGIR 2023 摘要法律案件检索旨在为查询案件找到相关案件，在智能法律系统中发挥着核心作用。尽管预训练在临时检索任务中取得了成功，但有效的法律案例检索预训练策略仍有待探索。与一般文档相比，法律案例文档通常是具有内在逻辑结构的长文本序列。然而，大多数现有的语言模型很难理解不同结构之间的长距离依赖关系。此外，与一般检索相比，法律领域的相关性对关键法律要素很敏感。即使关键法律要素上的细微差别也会显着影响相关性的判断。然而，现有的为通用目的而设计的预训练语言模型尚不具备处理法律要素的能力。 为了解决这些问题，在本文中，我们提出了SAILER，一种用于法律案例检索的新的结构感知预训练语言模型。突出表现在以下三个方面：（1）SAILER充分利用法律案例文件中包含的结构信息，更加关注关键的法律要素，类似于法律专家浏览法律案例文件的方式。(2)SAILER采用非对称编码器-解码器架构来集成多个不同的预训练目标。通过这种方式，跨任务的丰富语义信息被编码成密集向量。（3）SAILER即使在没有任何法律标注数据的情况下也具有强大的判别能力。能够准确区分不同罪名的法律案件。对公开可用的法律基准进行的广泛实验表明，我们的方法在法律案例检索方面可以显着优于以前最先进的方法 表1：介绍法律相关性的示例。这两段文字非常相似，但由于关键的法律要素，在法律上不相关。 A段：X人，24岁，男性，身高180厘米。2018年，他5次进入商场，盗窃手机一部、平板电脑两台，价值1000万。五点钟，他回到家，将上述物品交给Y人。 B款：X人，24岁，男性，身高180厘米。2018年，他5次进入商场，购买了一部手机、两台平板电脑，总价值1000万。五点钟，他回到家，将上述物品交给Y人。 引言 法律案例检索在现代法律体系中起着重要作用。为了实现正义和公平，在法律专家做出判决之前，找到并分析特定案例的相关先例是必要的。近年来，随着法律案例文件数量的激增，在整个语料库中找到相关案例变得越来越具有挑战性。因此，法律案例检索系统的研究受到法律和信息检索社区的重视[2,3, 24, 31,38]。在特定领域（如法律案例检索）中，构建高质量的带注释数据集通常需要大量的人力和领域专业知识，因此具有禁锢性。然而，最先进的检索系统通常基于使用大规模带注释数据进行训练的神经模型构建而成。因此，信息检索研究人员提议利用预训练语言模型（PLM），即在语言理解方面无需监督数据进行训练的大规模神经模型，来进行有效的检索[13,17, 36, 43]。先前的研究[7, 10, 16, 42]表明，诸如BERT [9] 和RoBERTa [18]等PLM在段落和文档检索数据集（如MS MARCO和TRECDL）上在零样本和少样本设置下明显优于现有的神经检索模型[8, 25,35]。尽管它们在临时检索和开放领域搜索中的性能优越，但是预训练语言模型在法律案例检索中的有效性尚未观察到。与传统检索任务相比，PLM应用于法律案例检索呈现出两个被现有研究忽视的非平凡挑战[31]。 挑战1：法律案例文件通常是具有固有写作逻辑的长文本序列。如图1所示，在案例法律系统和法令法律系统中，案例文件通常包括五个部分：程序、事实、推理、决定和尾部（我们将在第3节讨论这些部分的细节）。每个部分代表一个特定主题，字数从数百到数千不等。这些部分以标准法律逻辑编写，通常彼此相关。现有的PLM要么具有有限的文本建模能力，阻碍了其对长文档的建模能力[9,18]，要么忽视了法律案例文件的结构，使其无法捕捉法律写作逻辑中的远距离依赖关系[34]。因此，基于普通PLM的检索器的性能受到限制。 挑战2：法律领域中的相关概念与一般搜索中的概念有很大不同。在法律案例检索中，两个法律案例之间的相关性对其关键法律要素（例如“强行占用他人财产”，“任意毁坏他人财物”等）敏感。这里的关键法律要素包括关键情节和关键情节或因素的法律概念抽象[24]。没有关键法律要素或具有不同关键法律要素的案例可能导致不同的判决。例如，如表1所示，在临时检索中，这两段通常被认为是相关的，因为它们共享大量关键词和句子。然而，在法律案例检索中，这两段是不相关的，并且由于关键法律要素的影响可能导致完全不同的判决。在没有指导的情况下，开放领域PLM-based神经检索模型难以理解关键法律要素，在法律领域中的检索性能不佳。 为了应对这些挑战，我们提出了一种面向法律案例检索的结构感知预训练语言模型（SAILER）。SAILER采用编码器-解码器架构明确地对法律案例文件的事实和其他部分之间的依赖关系进行建模和捕捉（挑战1）。同时，SAILER利用推理和决定段落中的法律知识来增强对关键法律要素的理解（挑战2）。具体而言，我们使用深度编码器将事实段落编码为密集向量。然后，在事实向量的帮助下，分别将两个浅解码器应用于推理和决定段落中的被大幅屏蔽的文本的重构。 这样，SAILER充分利用了法律案例文件中的逻辑关系和不同结构中的知识。为验证我们方法的有效性，我们在中文和英文法律基准测试中进行了大量实验。实证实验结果表明，SAILER相对于最先进的基线模型可以取得显著改进。我们总结本文的主要贡献如下： (1)我们提出了一个针对法律案例检索的新型预训练框架，即SAILER，这是首个利用法律案例结构进行预训练的工作。 (2)我们提出了几种预训练目标，通过模拟法律案例文件的撰写过程，捕捉不同结构之间的长距离文本依赖关系和内在的写作逻辑知识。 (3)我们对公开的中文和英文法律基准进行了大量实验。实验结果表明，在法律案例检索中建模长距离文本依赖和利用结构知识的益处。 图1：法律案例结构图解。左案例来自美国（判例法体系），右案例来自中国（成文法体系）。标准法律案例文件可分为五个部分：程序、事实、推理、决定和尾部。 2 相关工作2.1 针对密集检索的预训练语言模型密集检索（DR）通常使用双编码器分别对查询和文档进行编码，并通过简单的相似性函数（余弦或点积）计算相关性得分。许多研究者通过负采样和蒸馏进一步提高了密集检索的性能[6,12, 26, 37,42]。信息检索领域的研究者已经开始设计针对密集检索的预训练方法[14, 15, 19,21, 22, 32,33]。这些方法主要旨在更好地表示带有[CLS]嵌入的上下文语义。它们基于[CLS]嵌入应编码给定文本中的重要信息以实现稳健匹配的直觉。例如，Condenser[14] 和 coCondenser [15]在编码器的最后层设计跳跃连接，以强制将信息聚合到[CLS]标记中。最近，基于自编码器的预训练引起了广泛关注。输入句子被编码为嵌入以重构原始句子，强迫编码器生成更好的句子表示。SEED-Encoder[21] 提议使用弱解码器进行重构。SIMIM [32] 和 RetroMAE [19]修改解码方法以加强信息瓶颈，从而提高生成嵌入的质量。 尽管取得了成功，基于自编码器的模型无法充分理解法律案例文件中不同结构之间的逻辑关系，因为它们主要依赖语料库中有限的信息。此外，由于案例文本包含许多对判断案例相关性不重要的事实，重构原始文本可能降低密集向量的区分力。 2.2 法律案例检索法律案例检索模型主要分为两大类[3]：基于专家知识的模型[30, 39]和自然语言处理（NLP）模型[5, 23, 31,34]。对于基于专家知识的模型，Zeng等人[39]扩展了传统法律问题元素，并引入了一组新的子元素用于表示法律案例。随着深度学习的发展，基于NLP的模型在法律案例检索中取得了巨大成功。Shao等人[31]将法律案例文本划分为若干段落，并使用BERT获取段落之间的相似度，实现了有前景的排名性能。PaheliBhattacharya等人[4]结合文本和网络信息来估计法律案例的相似性。近年来，许多研究者尝试设计预训练技术以在法律领域获得性能提升。例如，Chalkidis等人[5]从多个领域（如立法、法院案例、合同）收集了大量英文法律文本，并发布了LEGAL-BERT。Xiao等人[34]提出了针对较长法律文本的Lawformer，可以处理数千个标记的文档。然而，它们都没有针对法律案例检索设计预训练目标。我们认为，预训练模型的潜力尚未充分挖掘。 3 背景和基础知识在本节中，我们介绍法律案例检索的问题定义以及有关法律案例文档的初步知识。 3.1 问题阐述法律案例检索任务指的是从候选案例集中找到与给定查询案例相关的案例。形式上，给定一个查询案例𝑞 和一个候选案例集合 D，任务是从大型候选池中检索出前 𝑘 个相关案例 D𝑞 &#x3D;𝑑∗ 1,𝑑∗ 2, ……, 𝑑∗𝑘。为简单起见，我们专注于一种被广泛用于检索任务的双编码器架构[16,42]。该架构包括一个查询编码器和一个文档编码器，其主要目标是将文本映射到高维嵌入ℎ𝑞 和ℎ𝑑。在这里，文档编码器和查询编码器通常使用预训练语言模型进行实现或初始化，该模型通过接受原始文本作为输入产生嵌入表示（例如，[CLS]标记的嵌入）。然后，使用点积计算 𝑞 和 𝑑 的语义相关分数：𝑆 (𝑞, 𝑑) &#x3D;ℎ𝑞 · ℎ𝑑 (1) 如图1所示，候选案例包括事实 𝐹，推理 𝑅，决定 𝐷等部分。在大多数实际的法律案例检索场景中，查询 𝑞 仅包含基本的事实𝐹，而候选案例则是完整的案例文档。特别是，根据查询案例的基本事实，律师或法官使用法律案例检索系统寻找与查询案例相关的案例，以便更好地完成其下游任务，例如司法判决。在我们的工作中，我们遵循上述设置，并假设查询是法律案例文档的基本事实。 3.2 初步知识与 Web搜索等开放领域检索任务中的文档相比，法律案例文档通常具有更清晰但更复杂的结构。具体来说，在具有案例法律系统的国家，例如美国，法律案例文档通常包括程序、事实、推理、决定和尾部。程序部分介绍了当事人信息和诉讼状况。事实部分描述了当事人的论点、证据和基本事件。推理部分是法院选择规则并将其应用于事实的过程。在推理部分，法官解释了应用规则的原因。换句话说，在这个部分中反复提到与规则应用相关的事件，即关键法律要素。决定部分是法院基于案件关键事实给出的具体回应。推理部分和事实部分是法院决定的基础。尾部部分介绍了法院、法官等的基本信息。在具有法令法律系统的国家，如中国，法律案例文档具有相同的结构，但没有明确分成不同的部分。中国法律案例文档的结构是通过文本格式传达的。例如，“经审查”通常是事实部分的开头，“法院认为”之后通常是推理部分。尽管不同国家之间的法律制度和条款存在差异，但这些部分是完整法律案例文档的共同基础。 在实际审判中，编写法律文件的过程如图2所示。首先，原告的论点、被告的论点和它们的证据被呈现给法庭。法官们将其总结形成事实部分。然后，法官们确定与事实相匹配的法律和与事实相关的案例。在此之后，法官们提取关键法律要素，并根据这些要素解释法律的适用情况，以形成推理部分。最后，基于他们对案例和法律知识的理解，法官们做出最终的司法决定，例如诉因、处罚期限、赔偿金额等。在上述过程中，事实部分的重要信息将在推理部分中进行仔细分析，这将影响最终的决定。事实、推理和决定之间的这种逻辑连接对于理解和建模法律案例文档非常重要，这启发了我们提出针对法律案例检索的结构感知预训练语言模型。关于我们提出的方法的更多细节将在下一节中描述。 4 方法在本节中，我们详细描述了针对法律案例检索的结构感知预训练语言模型。为了将结构知识整合到语言模型中，我们模拟了法律案例文件的撰写过程，并提出了SAILER，如图3所示。SAILER主要由三个组件组成，即事实编码器、推理解码器和决定解码器。具体来说，在预训练过程中，我们使用类似于BERT的编码器来生成事实的向量表示，然后使用两个浅层解码器来重构推理和决定部分的文本。关于SAILER 的详细描述如下。 4.1 事实编码器在事实编码器中，我们首先随机用特殊标记 [MASK]替换事实的一些标记。只有少量的标记被替换，因为大多数事实需要被保留。特别地，我们将事实定义为𝐹 &#x3D; [𝑓1, 𝑓2, …, 𝑓𝑛]，掩码标记集定义为 𝑚(𝐹 )，其中 𝑓 表示标记，𝑛表示事实的长度。因此，其余标记可以表示为 𝐹 \\𝑚(𝐹 )。然后，被掩码的输入𝐹𝑚𝑎𝑠𝑘 被事实编码器 𝜙𝐹 (·) 转换为一个句向量。类似于之前的工作[9,14]，[CLS] 标记的最终隐藏状态被作为整个句子的表示： 与 Bert 类似，我们将被掩码的事实输入编码器以恢复 𝑚(𝐹 )并计算掩码语言建模（MLM）损失作为我们预训练目标之一。具体来说，MLM 损失𝐿𝑀𝐿𝑀 定义如下 4.2 推理解码器如上所述，推理部分包含案例的所有关键法律要素。因此，我们设计了推理解码器来模拟推理和事实之间的逻辑关系，旨在提高编码器关注点与案例文件中潜在关键法律要素之间的对齐度。具体来说，我们通过扰乱推理部分原始文本𝑅 &#x3D; [𝑟1, 𝑟2, …, 𝑟𝑛]来构建推理解码器。我们将推理文本分割为标记，并随机选择一个子集 𝑚(𝑅)进行掩码。采用了激进的掩码比例（30%-60%）用于语言重构。此外，密集向量 ℎ𝐹替换了原始的 [CLS]向量，通常用作解码器输入的起始部分。整个解码器输入被形式化为： 其中 erk 和 prk 表示 rk的嵌入和额外位置嵌入。这样，推理解码器的学习目标可以表述为： 推理解码器需要依赖于 ℎ𝐹 来恢复被掩码的推理部分，这迫使 ℎ𝐹专注于与事实中推理部分相关的有用信息。通过这种设计，SAILER增强了对关键法律要素的关注，并捕获了事实和推理之间的长期依赖关系。 4.3 决定解码器法律判决预测（LJP）旨在基于事实描述预测案件的判决结果[11]。如果两个案例具有相同的指控和法律条文，那么它们在向量空间中的密集向量应该更加接近。在这部分中，法律判决预测被建模为一个文本到文本的任务，使用决定解码器来帮助向量具有更强的区分能力。对于中国的法律案例，决定通常包括相关的法律条文、指控和处罚条款。给定一个决定部分𝐷 &#x3D; [𝑑1, 𝑑2, …,𝑑𝑛]，我们根据其指定的格式对其进行掩码。具体而言，决定通常格式化如下：根据中华人民共和国刑法【𝑧1】，被告犯有【𝑧2】罪，并被判【𝑧3】，其中𝑧1 表示具体的法律条文，𝑧2 表示指控，𝑧3 是处罚期限。我们使用 Z来表示所有被掩码的标记。在一些决定部分没有特定格式的国家，我们选择一定比例的具有高TF-IDF [1] 值的词语进行掩码。为方便起见，我们仍然将被掩码的标记称为Z。决定解码器也依赖于密集向量 ℎ𝐹来恢复原始的决定。具体来说，决定解码器的输入是： 其中 edk 和 pdk 表示 dk 的嵌入和额外位置嵌入。决策解码器的训练目标是： 简而言之，决策解码器巧妙地对法律判决预测任务进行建模，以帮助生成判别向量。 4.4 学习在预训练过程中，我们旨在优化以下训练目标： 在预训练完成后，我们丢弃了两个解码器并对编码器进行了微调。微调的目的是使查询在向量空间中与相关案例相比较于不相关案例更接近。因此，给定查询案例𝑞，假设 𝑑+ 和 𝑑 − 分别为相关和负面案例，损失函数 𝐿 定义如下： 遵循先前的工作 [26, 41]，负样本 𝑑 − 是 BM25的硬负样本。在训练过程中，对于每个查询案例采样许多负样本计算上是很昂贵的。因此，我们采用批内负样本[16]进行对比学习，以充分利用同一批次中的负样本。具体来说，如果一个批次中有 𝐵个查询，每个查询具有一个正样本和 𝑁个负样本，那么在训练期间，对于每个查询我们最多可以获得 (𝐵 − 1) ∗ (𝑁 + 个批内负样本。 5 实验在本节中，我们首先介绍了我们的实验设置，包括数据集和指标、基线和实现细节。然后，我们报告了实验结果来证明SAILER 的有效性。 5.1 数据集和指标我们在四个法律案例检索基准上进行了实验。统计数据如表2所示。 LeCaRD [24] 是中国法律体系下的第一个刑事案例检索数据集。LeCaRD中的查询只包含事实段落，而候选文档则是整个案例。每个查询有一个包含100个候选文档的文档池。 CAIL2022-LCR 是由 CAIL2022 3 提供的官方测试集，其格式与 LeCaRD 相同。 COLIEE2020 [28] 是由 COLIEE2020 4提供的官方数据集。每个查询有200个候选文档。参与者需要重新对每个查询的有限数量的案例进行排名。 COLIEE2021 [27] 是由 COLIEE2021 5提供的官方数据集。没有候选文档池，参与者需要从整个语料库中确定相关案例，使得检索任务比COLIEE2020 更加困难。我们在 LeCaRD 和 CAIL2022-LCR上报告了所有模型的零样本性能，因为注释查询的数量非常有限。对于 COLIEE2020和 COLIEE2021，我们直接使用两个数据集的合并训练集对基线和 SAILER进行微调，并在测试集上报告最终性能。我们遵循比赛中的评估指标。对于 LeCaRD和 CAIL2022-LCR，我们报告归一化折扣累积增益（NDCG）、Precision@5、Recall@5和 F1 分数。对于两个 COLIEE任务，我们报告平均倒数排名（MRR）、Precision@5、Recall@5 和 F1分数。具体来说，我们报告 COLIEE2021 的 R@100。 5.2 基线模型、我们采用三组基线模型进行比较：传统检索模型、通用预训练模型和面向检索的预训练模型。• 传统检索模型 BM25 [29] 是一种基于精确词匹配的高效稀疏检索器。 QL [40] 是另一种基于狄利克雷平滑的代表性传统检索模型。• 通用预训练模型 BERT [9] 是一个多层Transformer编码器，在即时检索任务中是一个强大的基线。 BERT_xs 6是一个针对刑法的BERT，在663亿份中国刑事裁判文书上进行了预训练。 RoBERTa [18]是BERT的增强版本，训练数据大幅增加。与BERT相比，RoBERTa只使用MLM任务进行预训练。 Lawformer [34] 是法律领域的第一个中文预训练语言模型，专注于处理长文档。 LEGAL-BERT [5]是使用大量英文法律文件进行预训练的语言模型，在多个任务中取得了最先进的结果。• 面向检索的预训练模型 Condenser [14]是针对即时密集检索设计的模型。它利用跳跃连接将文本信息聚合为密集向量。 coCondenser [15]在Condenser的基础上添加了一个无监督的语料库级对比损失，可以有效地热化向量空间。 SEED [21]从理论上分析了自编码器结构在密集检索中的不足之处。它使用弱解码器来增强编码器的训练过程。 CoT-MAE [33] 设计了高效的数据构建方法，以训练不对称的编码器-解码器架构。 RetroMAE [19]提出了增强的解码方法，使文本的重构更加困难，并在即时检索中取得了最先进的性能。 对于传统模型，我们使用默认参数的 pyserini 工具包 7进行处理。对于通用预训练模型，我们直接采用开源检查点来热启动模型参数。对于面向检索的预训练模型，我们使用与SAILER相同的法律预训练语料，并使用其论文中报告的最佳参数进行预训练。所有面向检索的预训练模型都是由BERT 初始化的。 5.3 实现细节5.3.1 预训练流程。为构建中文法律案例的预训练语料库，我们从中国裁判文书网 8收集了数千万份案例文档。我们将案例文档分为五个部分：程序、事实、推理、决定和尾部，使用正则表达式匹配。我们过滤了事实少于50个单词的简单案例。为了预训练英文模型，我们从美国联邦和州法院9收集了大量案例文档。与LEGAL-BERT不同，我们的预训练语料库只包含案例文档，不包括立法和合同。我们使用Huggingface 的 chinese-bert-wwm 10&#x2F;bert-base-uncased11初始化中文&#x2F;英文版本的 SAILER编码器，解码器是随机初始化的变压器层。默认的掩码比率为编码器为0.15，解码器为 0.45。我们使用 AdamW [20]优化器进行最多10个时期的预训练，学习率为1e-5，批次大小为72，线性调度的热启动比率为0.1。对于决策解码器，在中文案例中我们掩码法律条文、指控和处罚条款，而在英文案例中掩码具有更高TF-IDF [1]分数的单词。英文版本的决策解码器与推理解码器保持相同的掩码比率。 5.3.2 微调流程。对于微调，在给定一个查询时，我们使用 BM25从整个语料库中检索出前100个相关文档，将不相关文档视为硬负样本。我们使用AdamW [20]优化器进行最多20个时期的微调，学习率为5e-6，批次大小为4，线性调度的热启动比率为0.1。每个批次包含一个查询和十六个文档，这意味着正样本和硬负样本的比率为1:15。本文的所有实验均在8台NVIDIATesla A100 GPU上进行。 5.4 实验结果5.4.1 零样本评估。为验证 SAILER 的有效性，我们在两个中国刑法数据集上进行了零样本实验。SAILER与基线模型的性能比较如表3所示。从实验结果中得出以下观察：• 在零资源情况下，BM25 和 QL 在法律案例检索任务上提供了竞争性能。•通用预训练模型通常表现不如传统的词汇匹配方法。缺乏特定的预训练目标，如BERT等语言模型无法准确捕获法律案例检索中的相关性概念。•面向检索的预训练模型通常表现优于通用预训练模型。这表明，应用面向检索的预训练目标而不是通用的自然语言处理目标对检索任务是有益的。•令人惊讶的是，中文RoBERTa比使用大量刑法数据训练的模型更有效。没有下一句预测（NSP）任务，RoBERTa提升了[CLS]嵌入的稳健性。这可能表明，下一句预测任务对提高PLMs的检索性能并不有帮助。• 最后，我们注意到在两个数据集上 SAILER在大多数指标上都取得了最佳性能。没有任何监督数据，SAILER不仅明显优于其他预训练模型，而且是唯一击败传统检索方法的模型。这个观察结果表明，在没有可用的监督数据的情况下，将案例结构的知识纳入预训练过程是有效的，揭示了SAILER 在此类场景中的巨大潜力。 5.4.2 微调评估。如表4所示，我们在训练数据上将 SAILER与各种基线模型进行了比较。为了公平比较，不同的预训练模型利用相同的微调数据和相同大小的超参数。从实验结果中得出以下发现：• 在微调设置下，传统检索模型（如BM25、QL）在两个数据集上仍表现良好。•在有标注数据的指导下，预训练模型进一步得到改进。但是，在某些方面它们仍然不如传统的检索方法，例如，在COLIEE2021 的 R@100 指标上，QL 比大多数基线模型表现更好。• 总体而言，SAILER 在所有基线模型上都取得了改进。SAILER充分利用了法律案例的内在结构，通过上下文标记推断出专业知识。即使没有复杂的增强解码，它也能胜过RetroMAE。在 COLIEE2021 上，SAILER 是唯一超越 QL 在 Recall@100指标上的预训练模型，表明它能更好地区分大语料库中混淆的案例。由于测试案例数量有限，实际上之前的研究没有在COLIEE 数据集上进行显著性测试。尽管 SAILER 在 COLIEE2020 数据集上相对于SEED 和 RetroMAE 模型的改进不是非常显著，但 SAILER仍然实现了最先进的指标值。一般来说，参数大小相同的PLMs在微调后表现接近。因此，性能上的不显著改进也可以表明我们方法的有效性。 5.5 消融研究为了更好地阐明模型设计和预训练任务的有效性，我们在 LeCaRD数据集上进行了消融研究，采用零样本设置。表5展示了不同预训练目标的影响。SAILER_share是 SAILER的一个变体，其中推理和决策部分由共享的解码器重构。我们可以观察到，共享单个解码器导致了轻微的性能下降，这证实了我们多解码器架构的有效性。此外，我们分别移除了推理解码器和决策解码器，两者都导致了显著的性能下降。与移除决策解码器相比，移除推理解码器导致的性能下降较少。一个可能的原因是我们在推理解码器中使用的随机屏蔽不能有效地屏蔽所有关键法律要素，因此为SAILER提供了有限的指导。如何确定推理部分中关键法律要素的位置是我们未来工作的方向之一。最后，当移除所有解码器后，性能急剧下降。以上实验证实了我们预训练目标的有效性。 5.6 超参数分析5.6.1 屏蔽率的影响在这一部分，我们探讨了不同屏蔽率对 SAILER 的影响。我们在 LeCaRD数据集上进行了实验，其中编码器的屏蔽率从0变化到0.30，解码器的屏蔽率从0.15增加到0.60。结果如表6所示。有几个有趣的发现。（1）解码器屏蔽率的增加将使解码过程更加困难，模型性能在一定程度上会提高。当解码器屏蔽率高于0.45时，这种增长会变得不稳定。我们认为过度困难的解码可能对模型的学习是不利的。（2）适当的编码器屏蔽率有助于提高性能。然而，当编码器屏蔽率过高时，SAILER的性能会略微降低。这是因为过大的屏蔽率将阻止生成高质量的句子嵌入，考虑到在这种情况下大部分有用信息都将被丢弃。（3）总的来说，SAILER在广泛的屏蔽率范围内表现良好，显示出它的稳健性。当编码器屏蔽率为0.15，解码器屏蔽率为0.45时，SAILER实现了最佳性能。 5.6.2 解码器层数的影响。我们进一步探索解码器层数对性能的影响。我们在实验中保持了推理解码器和决策解码器的层数相同。实验结果如表7所示。随着解码器层数的增加，SAILER的性能下降，这与SEED [21] 的发现相似。总体而言，SAILER在解码器层数方面的性能非常稳健。 5.7 案例研究。为了进一步分析 SAILER的检索机制，我们在图4中可视化了单词的注意力权重，单词越暗表示其获得的注意力权重越高。为了公平比较，我们选择了与SAILER 使用相同解码机制来重构原始文本的 SEED 进行案例研究。SEED 和 SAILER的注意力分布存在许多差异。可以观察到，SEED 最关注 cofetol coughsyrup（一种药物的名称）、Guangzhou（城市名称）、Chen（人名）等。而 SAILER更关注影响最终判决的词语，比如 sold、drug、allowed等。值得一提的是，“allow”（允许）是这个案件的关键词，因为为吸毒者提供场所是一个典型的指控，意味着被告允许他人在自己的场所吸毒。我们可以观察到在SAILER 中，“allow” 被强调了。这表明 SAILER融入了法律知识，并更加关注关键的法律要素。 5.8 视觉分析。为了进一步探索 SAILER 的区分能力，我们使用 t-SNE对法律案件的向量分布进行可视化。具体而言，我们选择了六种易混淆的指控，包括故意伤害、挑衅、聚众斗殴、盗窃、抢劫和诈骗。对于每一项指控，我们从预训练语料库中随机选取了一定数量的法律案例。我们在零样本情况下利用现成的预训练模型生成了法律案件的向量。从图5可以看出，SAILER具有强大的区分能力。对于中文 BERT，它总是混淆不同指控的案件。虽然中文RoBERTa能够区分盗窃、抢劫和诈骗这三种指控，但它混淆了故意伤害、挑衅和聚众斗殴。通过重构原始文本，SEED学到了更多信息，并生成了均匀分布的向量。然而，相似指控的边界太接近，这对于法律案件检索是不利的。相比之下，SAILER能够更准确地区分不同指控的向量，而且没有任何监督数据，表明它通过我们的预训练目标学习了丰富的法律知识。 6 结论本文提出了SAILER，这是一个面向法律案件检索的新型结构感知的预训练语言模型。SAILER的关键思想是充分利用法律案件文档的结构关系进行预训练。通过重构关键法律要素和判决结果，SAILER生成了更好的法律案件表示，并具有更强的区分能力。通过在四个基准法律数据集上进行大量实验，SAILER在低资源和全资源设置下相对于基线模型取得了显著的改进。在未来，我们希望探索将更多专家知识，如法律知识图谱和法律条文，纳入预训练语言模型中，以实现更好的法律案件检索效果。","tags":["papers"]},{"title":"CaseEncoder_用于法律案例编码的知识增强预训练模型","path":"/2024/04/19/CaseEncoder-用于法律案例编码的知识增强预训练模型/","content":"CaseEncoder：用于法律案例编码的知识增强预训练模型Type: Academic JournalPublisher: EMNLP 2023Link: https://arxiv.org/abs/2305.05393 摘要法律案件检索是现代法律信息系统的一个关键过程。虽然最近的研究利用基于通用领域自监督预训练范式的预训练语言模型(PLM) 来构建法律案例检索模型，但使用通用领域 PLM作为骨干存在局限性。具体来说，这些模型可能无法完全捕捉法律案件文件中的基本法律特征。为了解决这个问题，我们提出了CaseEncoder，一种法律文档编码器，它在数据采样和预训练阶段利用细粒度的法律知识。在数据采样阶段，我们利用细粒度的法律文章信息来指导正例和负例的选择，从而提高训练数据的质量。在预训练阶段，我们设计了符合相关法律案件的判断标准的法律预训练任务。基于这些任务，我们引入了一种称为Biased Circle Loss的创新损失函数，以增强模型识别细粒度案例相关性的能力。多个基准的实验结果证明CaseEncoder在零样本法律案例检索中显着优于现有的通用预训练模型和特定于法律的预训练模型。CaseEncoder的源代码可以在https://github.com/myx666/CaseEncoder找到。 1 引言法律案例检索是现代法律信息系统的一个关键过程，其目的是找到相关的先例（即先例），为案件的裁判提供重要参考。近年来，预训练语言建模（PLM）技术在通用领域检索任务中取得了巨大成功，这也引发了将PLM应用于法律领域的尝试。例如，钟等人。（2019）和肖等人。 (2021) 分别提出了基于 BERT (Devlin et al., 2018) 和Longformer (Beltagy et al., 2020) 的面向法律的PLM。然而，现有的面向法律的PLM在适应法律领域方面存在局限性，因为它们主要依赖于用法律数据替换通用领域训练数据或扩展输入长度以适应法律文档的长长度特性。葛等人。(2021)以前提-结论对的形式解析法律文章，以训练法律案件的多级网络匹配。巴塔查里亚等人。(2022) 提出了HierSPCNet，它通过引入法律文本信息大大提高了基于网络的相似性。然而，他们仍然采用通用领域PLM 作为其方法的基础。虽然可以解释，但此类模型并不能完全使 PLM理解案例文档中的法律概念，这限制了它们的普遍性和适用性。 为了解决这个问题，本文提出了CaseEncoder，这是一种利用细粒度法律知识来改进数据采样阶段和预训练阶段的PLM。 在数据采样阶段，我们将法律文章分割成明确的分支，并在每篇文章中构建内部逻辑关系，用于估计案件之间的相似性权重。这些相似性权重充当伪标签来指导正面和负面案例的选择。通过这种方式，我们提出的数据采样方法提高了采样案例的质量，以进行进一步的预训练。 在预训练阶段，CaseEncoder采用掩码语言建模（MLM）和细粒度对比学习任务。这些任务旨在匹配法律关联性判断标准中的两个主要概念：关键情况和关键要素（Maet al.,2021b）。关键情况是指文件中对重大案件的描述，关键要素是对关键情况的法律层面的抽象，更注重与法律条款的一致性。在实践中，MLM任务捕获语义级案例描述，而细粒度对比学习任务采用样本案例及其相关权重来增强模型识别关键元素的能力。基于细粒度对比学习任务的设计，我们提出了一种创新的损失函数BiasedCircleLoss，它利用获得的细粒度相关性得分来优化关键元素的识别。将法律文章注释为细粒度的法律知识有两个优点。1）成本效率：无论何种法律制度，法律条款通常都是闭集，文件数量有限，而且法律条款的数量远小于现实中法律案件的数量。因此，注释法律文章比注释法律案例花费的精力要少得多。2）普遍性：文章中的法律知识适用于相应法律制度下的所有案件。值得注意的是，将法律条款注释为细粒度法律知识的思想可以适用于所有成文法体系，甚至适用于普通法体系，因为成文法是普通法最重要的渊源之一。 多个法律案例检索数据集上的实验结果表明，CaseEncoder的性能明显优于现有的通用预训练模型和专门针对法律的预训练模型。我们还展示了案例文件嵌入的可视化，以展示CaseEncoder在诸如罪名预测和条款预测等下游任务中的潜力。 2 相关工作法律案例检索方法可以分为两类：传统的词袋方法和基于神经网络的方法。在深度神经网络出现之前，TF-IDF+VSM（Saltonand Buckley，1988）、BM25（Robertson et al.，1995）和LMIR（Ponte andCroft，1998）是代表性的词袋方法。这些方法有一个共同的特征：它们都将文档视为一系列术语，并通过术语频率或逆文档频率等统计因素来计算文档相似度得分。 这种方法的一个局限性是它们忽略了术语之间的顺序信息。随着自然语言处理技术的快速发展，将预训练语言模型（PLM）应用于法律案例检索取得了巨大成功。韦斯特曼等人。（2020）；邵等人。 (2020) 通过微调的 BERT 直接检索法律案例 (Devlin et al.,2018)。钟等人。 （2019）和肖等人。 (2021) 使用大型中国法律语料库分别预训练BERT 和 Longformer。除了将原始 PLM应用于法律领域之外，还有一些工作试图将法律知识纳入其提出的模型中。例如，孙等人。(2022) 提出了Law-Match，这是一种与模型无关的因果学习方法，利用法律文章中的知识来解决法律案例匹配。巴拉莱等人。（2023）将检索、处理和信息提取整合到一个管道中，以识别难民案件中的关键信息。他们的模型从难民案例中检索了总共19类物品，然后通过最先进的神经命名实体识别方法进行信息提取。巴塔查亚等人。(2022) 将基于领域知识的文档相似性纳入 PCNet (Minocha et al.,2015)，并提出一种称为 Hier-SPCNet的异构网络，以更好地表示文档相似性。然而，这些基于神经的工作都需要针对特定任务的微调或对齐才能达到相对较好的性能。相比之下，我们提出的方法可以直接应用于零样本设置中的不同下游任务。 3 任务定义 给定一个查询案例 q，该任务旨在从候选列表 L &#x3D; {c1, c2, …, cM }中检索相关案例，其中 M 是 L 的大小，并根据与 q的相关性对它们进行排序。清单中的每个候选案件文件都包含三个主要组成部分： 1.事实是法院根据被告和原告提供的证据确认的客观事实陈述。这些陈述通常回答诸如案件发生地点、时间和方式等问题。2. 裁定是法官对案件关键论点的意见。它解释了法官决定背后的理由。3、决定书包含对被告人的最终判决，包括罪名、刑罚、涉案条款等。该部分是案件的正式结果。一个法律案件文档的例子如图1所示。在真实的法律案件检索场景中，q通常是一个待判案件。因此，q仅包含案件的事实，而候选案件是具有完整文档的先例，包括标题、元信息、事实、控股、判决和相关法律文章。在本文中，我们主要关注刑法下的案件检索。为了匹配检索模型以前可能从未见过q或其相关案件的真实法律场景，本文中所有模型都以零样本的方式进行评估。 4 方法本节概述了CaseEncoder的设计和实现。图 2展示了该模型的总体框架。我们首先介绍 4.1节中用于数据准备的细粒度案例抽样方法。然后，在 4.2 节中，我们描述了CaseEncoder 中提出的预训练任务。 4.1 细粒度案例抽样最近针对法律方向的预训练语言模型研究并未专注于从自下而上的角度理解法律文本。换句话说，大多数预训练语言模型仅仅是将通用领域的训练语料库替换为法律文本，而没有考虑这些文本之间的法律相关性。这主要是因为对法律案例进行标注耗时且需要大量专业知识，使得收集大规模标记数据具有挑战性。另一方面，在已被证明在预训练阶段有效的对比学习中，数据需要事先被采样为正负案例。不同于通用领域，在法律领域中，仅仅基于文档中的原始信息（例如罪名、法律条文等）对正负法律案例进行抽样并不足够合适。因为在真实的法律场景中，法官通常根据案件的关键情况和要素（对法律条文的细致解释）来裁决案件。因此，本文提出了一种针对法官决定案件特定过程的精细化抽样方法，用于法律案例文档。通过这样做，抽样得到的正负案例可以尽可能与随后的对比学习任务中的手动标记的相关性相匹配。 通常，一条法律条文涵盖多个分支。一个分支描述符合该条文的具体且明确的情况。例如，图3中显示的中国刑法第133-1条有四个行为，其中行为（1）、（2）和（4）分别描述一个确定的分支，但行为（3）使用两个“或”子句来涵盖所有分支。具体地，“从事校车服务”和“从事客运服务”属于不同的分支，即使它们属于同一条文，也不会出现在同一个案例中。在本文中，我们称这种并列关系中的短语。根据乘法原理，行为（3）描述了2× 2 &#x3D; 4个分支。因此，第133-1条总共有1×3+4 &#x3D;7个分支。根据第133-1条，一个条文中的短语不仅可以按顺序编写，还可以以并列的方式。换句话说，一个法律条文的结构是复杂的。即使对于属于同一条文的两个案例，如果没有任何详细信息，模型很难识别它们之间的法律相关性，因为这样的案例可能属于该条文的不同分支。为了应对这一挑战，在法律案例中，法律条文的信息需要在更加细致的层面上进行进一步探索。在本文中，我们确定了更加精细化的条文信息，即分支级别的相似性，作为找到我们案例抽样算法中正负案例的初步步骤。 为了获得法律案例的分支级别相似性，首先需要从所有法律条文中提取分支。如图3所述，提取和预处理包括以下步骤：首先，将所有法律条文拆分成短语。然后，属于同一条文的短语被重构为分支。类似于第133-1条的例子，按顺序编写的短语属于同一分支，而并列关系中的短语属于不同分支。最后，我们将每个分支拆分为单词，并移除所有无意义的词语（例如，停用词、介词）。一个分支中剩余的单词被称为一个序列。属于同一法律条文的所有这些序列构成了一篇法律文章的语料库。总之，具有N条文的法律系统有N个文章语料库： 这里T是文章#p中序列的数量（即分支的数量）。借助文章语料库，我们可以获得案例的精细法律特征。具体而言，我们首先从案例文档中提取Holding，其中包含支持最终裁决的理由，并与案例的条文高度相关。在法律领域，犯有相同罪行的案例具有共同的条文。因此，我们的案例抽样策略可以利用文章语料库识别它们之间的细粒度法律相似性。假设案例ci属于文章#p且案例ci的提取的Holding为hi，我们可以通过以下方式计算细粒度法律特征vip： 这里f (seqpq,hi)表示文章#p的第q个序列和hi给定语料库Ca之间的BM25（Robertson等人，1995年）分数。在这里使用BM25的原因是实验结果显示，代表术语级别相似性的传统和精心设计的复杂方法之间的差异很小。vip可以直观地解释为细粒度文章级别的法律案例特征之一。接下来，给定两个案例ci和cj，两个案例之间的细粒度相似性权重wij可以表示为： 这里Ai是涉及案例ci的文章集合，cos是余弦相似度分数，k表示Ai中第k个文章。换句话说，两个案例之间的细粒度相似性权重主要由两个方面决定：两个案例之间的文章重叠程度以及它们的细粒度法律特征vik和vjk之间的余弦相似度。注意，在方程4中添加了一个最大函数，因为wij由Ai∩ Aj中所有文章的最相似情况给出。 最后，对于法律案例语料库中的每个案例ci，细粒度抽样方法可以根据wii+值抽样出一个在法律上可解释的正例案例ci+，这可以被视为指示法律相关性的伪标签。 细粒度采样方法：针对每个法律案例 **ci**，根据相应的 wii+值（在公式中描述的细粒度相似性权重），该方法能够选择并采样出一个合乎法律相关性的正样本案例**ci+**。这里的 wii+ 本质上是一个权重值，代表了案例 ci与另一个法律相关案例 ci+之间的相似度，用作一个伪标签，指示了案例之间的法律相关性程度。 伪标签作用：这个伪标签 wii+被用来指导预训练过程中数据的选择。在预训练阶段，为了强化模型对案例之间法律相关性的理解，这些法律相关的正样本ci+ 被选择作为训练样本的一部分。这些样本与原始案例 ci一起形成了一个四元组的形式：**(ci, ci+, vip, vi+p)**，其中 vip 和vi+p 是案例 ci 和 ci+的细粒度法律特征（根据公式4计算），而 p是在公式4中得到最大余弦相似度的法律条文的索引。 4.2 法律类预训练任务作为面向法律的预训练模型，我们的目标是将法律知识融入到预训练任务的设计中，以便模型在训练后不仅能在语义层面理解案例文档，还能在法律概念层面进行理解。为此，在本文中，我们参考相关案例的判定标准来设计我们的预训练任务。正如Ma等人（2021b）所示，如果两个案例满足两个要求，即它们的关键情况之间相似度高，以及它们的关键要素之间相似度高，则认为两个案例相关。具体而言，关键情况指重要的案件描述，而关键要素更关注与法律条文的一致性，并代表了关键情况的法律层面抽象。总结而言，当案例描述和抽象的法律概念都相关时，一个案例被认为与另一个案例相关。考虑到在其他自然语言处理任务中的整体表现，我们选择了中文RoBERTa（Liu等人，2019）作为CaseEncoder的主干。根据这个判定标准的理念，CaseEncoder通过两个任务进行预训练，分别用于识别关键情况和关键要素。 4.2.1 预训练任务14.2.1 预训练任务1第一个预训练任务是遮盖语言建模（MLM）任务，它能够捕获案例描述的常规语义级别含义。正如Devlin等人（2018）；Liu等人（2019）；Ma等人（2021a）所讨论的那样，MLM有助于生成具有上下文信息的嵌入。这些嵌入对于表征法律案例中的关键情况非常有益。具体而言，我们仅选择案例文档中的事实部分，随机遮盖其中的15%标记用于MLM，因为关键情况都包含在事实部分中。然后，遮盖的文本被输入到CaseEncoder中，根据周围未遮盖的标记来预测被遮盖的标记。MLM损失函数被定义为其中x是事实部分的文本，m(x)是被遮盖的标记集合，x\\m(x)是未被遮盖的标记集合。 4.2.2 预训练任务2第二个预训练任务是一项精细级对比学习任务，利用了在4.1节中获得的四元组（ci、ci+、vi、vi+）的信息。先前工作中的对比学习任务（Chen等人，2020年）使用增强的正例来训练模型，并将同一批次中的其余案例视为负例。然而，在法律领域，相关性的尺度更加精细。一个法律案例可能部分相关于另一个案例，相关性程度主要由先前提到的关键要素决定。因此，提出了一项精细级对比学习任务，以增强关键要素的识别。 具体来说，假设批次大小为N，每个四元组有两个案例，在一个批次中的案例总数为2N。首先，采用多层Transformer来获取2N案例的表示。然后，我们将Transformer最后一个隐藏层中的[CLS]标记的输出作为案例嵌入：e1、e2、…、e2N，ei∈ RH，其中H是隐藏大小。最后，这个精细级对比学习任务的训练目标，称为BiasedCircle Loss（BCL），被定义为： 这里sp和sn分别是正例和负例案例嵌入对之间的余弦相似度分数。αp和αn是控制收敛速度的参数，其中αp由方程式4中的法律特定相关权重确定。γ、Op、On、∆p和∆n是尺度因子、sp的最优、sn的最优、类间间隔和类内间隔的超参数。 通过这种方式，CaseEncoder被训练以将同一类别中的案例嵌入拉近，并将不同类别中的案例嵌入推远。案例嵌入在向量空间中的距离取决于sp和sn的值。我们提出的损失函数与CircleLoss（Sun等人，2020年）有两个主要区别：首先，我们将原始损失函数从二元设置扩展到多类设置，因为批次中的法律案例可以被分类为多个类别。具体来说，如果两个案例的法律特定相关权重大于特定阈值WT，则我们认为它们属于同一类别，并且这样的规则在批次中的所有案例上都是传递的。因此，方程式6的实际实现更为复杂，因为案例属于多个类别。其次，我们在LBCL中添加了权重参数α，以考虑案例之间相关性的程度。因此，优化目标会根据w的值而变化。通过考虑法律特定的相关权重，CaseEncoder被训练以细分相关案例。最后，CaseEncoder通过MLM损失和BCL损失的线性组合进行优化：这里λ是一个超参数。 5 实验5.1 数据集和评估指标本文采用三个公开可用的数据集：LeCaRD、CAIL2021-LCR 和CAIL2022-LCR。LeCaRD（马等，2021b）是第一个中文法律案例检索基准，被广泛用于检索模型的评估。《法律人工智能挑战赛》（CAIL）（肖等，2018）是自2018年以来每年举办的一项竞赛，旨在推动人工智能技术和数字司法的更高水平。CAIL2021-LCR1 和 CAIL2022-LCR 2是CAIL的两个竞赛数据集。值得注意的是，由于实验设置是零-shot，正如在第4节介绍的，本文提及的所有方法都不需要训练或微调阶段。因此，数据集中的训练集和测试集均包含在评估中。这些数据集涉及的法律文件总数为537。作为一个检索任务，在本文中，所有模型都是通过标准化折减累积增益（NDCG）指标进行评估的。在本文中，我们考虑了三种不同的NDCG指标：NDCG@10、NDCG@20和 NDCG@30。 5.2 基线为了全面评估CaseEncoder在法律案例检索上的性能，在本文中，我们采用了以下在法律领域广泛应用的PLM作为基线：•BERT-XS（钟等，2019）是BERT（Devlin等，2018）的新版本，它对中文刑事文件进行了二次预训练。与原始的BERT相比，BERT-XS主要专注于法律领域特定的任务。•Lawformer（肖等，2021）是第一个面向法律并基于longformer（Beltagy等，2020）的语言模型，它结合了任务驱动的全局注意力和局部滑动窗口注意力来捕获远距离信息。Lawformer将输入长度从512个标记扩展到4096个标记，以适应法律文件的长长度。•BERT-PLI（邵等，2020）聚合了两个案例文档之间的段落级语义相似性以检索法律案例。作为BERT-PLI的主干，使用COLIEE2019（Rabelo等，2019）的案例法数据集对BERT模型进行了微调以实现对齐。 RoBERTa（Liu等人，2019年）是对BERT（Devlin等人，2018年）的复制，广泛研究了超参数设置和训练数据大小。对各种自然语言处理任务的实验结果显示，RoBERTa能够达到或超过许多先前的预训练语言模型的性能。由于本文中所有数据集都基于中国的法律系统，我们采用了中文版本的RoBERTa（Cui等人，2019年）作为基线。 •RoBERTa-Legal是RoBERTa的法律版本，通过MLM任务对法律数据进行了二次预训练。 • OpenAI API3是获取由OpenAILLMs生成的文本嵌入的官方公开方式。在本文中，我们采用OpenAI提供的第二代嵌入模型text-embedding-ada002（Brown等人，2020年）来衡量法律文件的相似性。 5.3 实施细节为了进行公平比较，CaseEncoder和基线以相同方式用于检索法律案例。具体来说，所有模型采用常用的双编码器范式来检索法律案例。也就是说，模型分别使用查询的全文和候选案例的事实部分来生成文档级别的查询嵌入和候选案例嵌入，而无需任何二次预训练或微调。 最终检索的排名列表是根据查询嵌入和候选案例嵌入之间的余弦相似度进行排序的。所有PLMs均来自Huggingface（Wolf等人，2019年），学习率设置为1 10^-5。 BM25算法由Gensim（ˇReh ̊ uˇrek等人，2011年）实现。CaseEncoder的超参数为：γ&#x3D; 16，Op &#x3D; 1.25，On &#x3D; 0.25，δp &#x3D; 0.75，δn &#x3D; 0.25，WT &#x3D; 0.25，λ &#x3D; exp∗10^-6。所有训练和实验均在八个32G的NVIDIA V100 GPU上进行。 5.4 实验结果CaseEncoder和基线在LeCaRD、CAIL2021-LCR和CAIL2022-LCR数据集上的整体表现如表1所示。通过实验结果，我们得到以下观察： •与基线相比，CaseEncoder在三个数据集的所有评估指标上都取得了最佳结果。此外，CaseEncoder在除了一个结果（即CAIL2021-LCR上RoBERTa-Legal的NDCG@30）之外的其他结果中都以显著的差距（即0.855到0.876）领先于基线。这个现象说明了CaseEncoder在没有任何微调的情况下检索法律案例的有效性。知识增强的采样策略和预训练任务有助于检索具有法律意义的相关案例。 •LeCaRD的整体结果普遍低于CAIL2021-LCR和CAIL2022-LCR数据集。这主要是由于数据语料库的异质性造成的。具体来说，LeCaRD中候选文档的汇总没有任何限制，而CAIL2021-LCR和CAIL2022-LCR则排除了长度极长的文档。因此，LeCaRD比其他两个数据集更具挑战性。 •作为CaseEncoder的骨干，RoBERTa在所有基线中表现出竞争力，这是一个与其在其他自然语言处理任务上的表现一致。此外，RoBERTa-Legal具有第二最佳的整体表现，并且优于原始的RoBERTa，这证明了Gururangan等人（2020年）的观点：使用领域特定数据进行二次预训练有利于目标领域的整体性能。最后，CaseEncoder优于其骨干模型及其法律版本的骨干模型，这表明CaseEncoder的有效性不仅仅取决于训练数据。 •BERT-XS（钟等人，2019年）的有效性受到限制，因为它利用了下一句预测（NSP）任务进行预训练，其[CLS]标记并未经过训练以表示文档级别的嵌入。此外，BERT-PLI并不如Shao等人（2020年）报道的那样有效。一个可能的解释是，BERT-PLI利用了COLIEE2020（Rabelo等人，2020年）中蕴涵任务的数据集作为外部法律数据源来微调模型。为了进行公平比较，本文中不导入任何外部数据进行进一步训练。因此，与Shao等人（2020年）报告的结果相比，BERT-PLI的性能下降了。 •OpenAI提供的嵌入式LLM在零shot法律案例检索方面并不像在一般领域中那么有效。其整体性能甚至被参数规模更小的PLMs（例如RoBERTa和RoBERTa-Legal）超越。这一结果表明，目前，在一般领域中的LLM并不是法律案例检索的最佳选择。 5.5 消融研究为了调查我们提出的精细级抽样方法、知识增强对比学习任务以及我们提出的BCL损失函数的有效性，我们进一步进行了消融研究。具体来说，我们：1）用常规的批内抽样（同一文章中的案例简单地被视为正例）替换我们的抽样方法，2）用infoNCE（Oord等人，2018年）替换BCL损失，3）用CircleLoss（Sun等人，2020年）替换BCL损失，4）分别移除精细级对比学习任务。如表2所示，替换抽样方法、BCL损失函数或移除对比学习任务都会导致性能下降。因此，本文提出的所有这些创新都对CaseEncoder的有效性有所贡献。表2中的结果还表明，BCL对于CaseEncoder的改进贡献最大。传统的二元对比学习任务对性能的贡献有限，因为移除整个对比学习任务与用infoNCE替换BCL具有类似的性能，这意味着改进主要是由BCL实现的。 5.6 案例嵌入的可视化CaseEncoder旨在有效地对法律领域的案例文档建模。除了检索任务外，文档级别的案例嵌入还可用于其他下游任务，比如罪名预测、句子预测和法律条文推荐。因此，文档级别案例嵌入的质量是下游任务性能的基础。图4是CaseEncoder如何提高罪名预测案例嵌入质量的示例。图4中的案例属于六种刑事罪名。对于每种罪名，我们从法律语料库中随机选择2500个案例，并使用四种不同的方法生成它们的案例嵌入。然后，我们使用tSNE（VanderMaaten和Hinton，2008年）来降低案例嵌入的维度以进行可视化。在所有PLMs中，CaseEncoder具有将案例嵌入基于其罪名划分为六个簇的最佳能力，只有一对类似的罪名（Provocation和PublicBrawl）存在部分重叠。相比之下，RoBERTa部分区分了六种罪名，但比CaseEncoder有更多的重叠。BERT-XS和Lawformer的性能受限，与第5.4节中的检索结果和解释一致。这些可视化展示了CaseEncoder中嵌入的精细法律知识如何能够在案例检索之外的一系列法律应用中发挥作用。 6 结论和局限性本文提出了CaseEncoder，一种利用精细法律知识增强案例文档嵌入表示的预训练编码器。通过将法律条文标注引入抽样方法，我们在数据准备过程中改善了抽样正负案例的质量。接下来，在预训练阶段，CaseEncoder采用了两个法律特定的预训练任务，以与法律领域的相关判据相一致。实验和视觉分析证明了CaseEncoder生成的案例嵌入在解决零shot法律案例检索中的有效性。 CaseEncoder的主要局限性是：首先，相似法律案例的定义是基于”犯同一罪行的案例具有共同的条文”的假设，这并不适用于所有法律体系。然而，将法律条文注释为精细的法律知识以增强PLMs性能的想法有潜力被其他法律体系采纳。未来，我们将考虑验证CaseEncoder在不同法律体系和语言的数据集上的有效性。我们还将探索CaseEncoder在不同下游法律任务中的潜力。其次，第4.2.2节中的传递规则在所有情况下并不一致。例如，假设案例A和B属于同一类别，B和C也属于同一类别，那么如果案例A和C都属于多个类别，则案例A和C可能没有共同的法律条文。根据我们的实验结果，在预训练阶段减小批次大小可以减轻这种特殊情况的影响，因为随着批次大小的减小，出现两个多类案例出现在同一训练批次中的可能性也下降了。我们将把我们提出的BCL函数的优化留作未来的工作。","tags":["papers"]},{"title":"倦怠社会","path":"/2024/04/19/倦怠社会/","content":"Author: 韩炳哲Summary: 现代功绩社会主体心理的映照Type: Article 开篇，作者指出神话故事里的普罗米修斯，就是倦怠社会里自我剥削式主体最初的隐喻。 古希腊神话中，普罗米修斯因为帮人类盗取火种，而被罚绑在山崖。宙斯每天派秃鹰白天啄食他肝脏，夜晚他又重新长出肝脏，这样普罗米修斯就承受着一种日复一日永无止境的折磨，被一种类似倦怠感的痛苦控制。 作者认为这就是现代功绩社会主体心理的映照：自身对自身施加暴力。 《倦怠社会》里所言“暴力不仅源于否定性，也源于肯定性；不仅来自他者或外来者，还来自同类。”这种自我施暴的剥削十分隐蔽。就像没人会责怪抖音的推送太过有趣，只会反思自己没有自制能力。我们可以反抗他人的压迫，却没法抵挡自我的“剥削”；我们以为自己可以在功成名就后退隐山林，实际上却早已在资本的裹挟下面目全非。 作者认为，过去人们处于传统的规训社会。在规训社会里，社会存在种种规定和禁令，给人们的自由带来很多束缚和限制。但也因为有规定的存在，社会剥削是存在边界的。 “21世纪的社会不再是一个规训社会，而是功绩社会。其中的成员也不再是驯化的主体，而是功绩主体。” 随着社会发展，人们进入了功绩社会。在功绩社会里，人们不再受外在的强权机构控制，也没有外力强迫剥削个人。 “但是摆脱了强权机构控制后，人们并没有导向自由，因为自由和约束几乎在同一时刻降临。”——原文摘抄 功绩社会里，人们投身于一种自我约束中，以达到“功绩”的最大化。当追求“功绩”日益严重时，自我约束发展成为了一种自我剥削。 “因为自我剥削伴随着一种自由的感觉。功绩主体不断剥削自我，直至精力枯竭。他发展出一种自我攻击，并往往以自我毁灭为终结。”——原文摘抄 外在的约束尚有边界，而这种自我的约束是360度全方位、无尽无边的。在功绩社会，自我剥削比他者剥削更有效率。功绩社会的一代人，终日伴随着疲劳、抑郁、不可摆脱的倦怠感。 简而言之，社会从资本家强迫劳动者、剥削劳动者的社会，变成了我们自愿自动压迫和剥削自己的社会。 凯恩斯预测大家有一天都会达到小康状态，从而感到满足，因为新增的收入会越来越没有意义，大家就不再追求更多的东西。然而现状，大家都看到了：宁愿卷死自己，也要累死他人才是常态。 功绩社会，大家都努力，你不努力就容易出现自我否定。但在不停的努力中，必然会出现倦怠。 超过一定经济水平以后，人们大部分的金钱，都用于购买从绝对意义上并不真正需要的东西，但拥有这些东西意味着快乐、优越感、自我感觉良好。用一个网红的词语大概是：炫耀性消费。 但普通大众是无法克服人性的，每个人都是在跟别人的比较中，定位自身，形成自我身份认证的。 作者韩炳哲认为现代互联网科技发展，以“点赞文化”为代表加速了功绩社会的发展。 互联网科技带来了过度的刺激、信息和资讯，从根本上改变了人们注意力的结构和运作方式。 人们的感知因为过多的信息变得分散，反过来影响时间管理方式——习惯多工作业。但这种多工作业方式并不是人类新掌握的技能，代表文明进步，确切说反而是一种倒退。这种过度刺激，会带来过度的“积极性”，刺激人们更多地去自我剥削。 随着生产力发展，自我剥削日益加剧，让工作和生活失去了目的和意义，生成难以克服的倦怠感。 “提高或者降低工作速度，并不能解决当下的危机，我们需要一种全新的生活心态，把我们从飞转的停滞状态中解救出来。”——原文摘抄 现代社会是一种强制的自由，即我们处于拥有自由的假象和幻影中。书本里称21世纪的社会是功绩社会，而我们则是功绩主体，相比于规训社会里的规训主体，功绩主体无须屈从任何人，或者说只屈从于自身，但尽管摆脱了统治机构，却没有导向自由，自由和约束几乎在同一时刻降临。 “一个人同时是囚犯和看守，受害者和施暴者”这句话是“强制自由”最好的印证。过量的正反馈会导致既定目标的偏离，过度的活跃也会转变为一种过度的消极，我们失去了否定、消极、愤怒以及沉思的能力，“生命在现代变成了生存”。 在我们这个倦怠的社会里面有了一个新的问题，我们绝不允许自己有一丝的无聊。 过度的这种社会的积极性呈现给我们的是一种过度的一种刺激，每天都在刺激我们，大量的信息和资讯。因为我们肯定了自己的这种无限可能了，所以我们需要不断的拓展自己，我们每天开始疯狂的看资讯学习，要突破自己。 于是有个电影台词说的，现代人再也不会留意日落了。 这个留意日落的状态其实它本身就是一种我们理想的一种无聊。 韩敏哲在这里认为，我们涣散的这种注意力，其实反而他并不会产生新的事物了。他只会重复或加速已经存在的事物，我们看似获得了无数的讯息和知识，疯狂的在运转自己。但其实我们把面铺的越广就越不会深入他。你害怕无聊，当5分钟过去了，你感到无聊了，就会马上寻找新的一个替代品。于是短文字短视频就成为我们的这个时代的新欢，他和过去的一生只能做一件事形成了两个极端。 而只有深度的这种注意力才会创造新的文化，这种深度的注意力恰恰来自于一种深度的无聊。 也许到了功绩社会的晚期，人们普遍就会觉醒了。我们下一次的思想革命的对象可能就是推翻剥削自我的那个自我。我们从疲劳的倦怠走向一个亲近世界的倦怠，疲劳的倦怠，使人相互的对立。而亲近世界的倦怠是我们坐在傍晚的湖边从工具的人中走出来，成为自然的人，自我松动，不再向内剥削了，而是向着世界延展。人的心灵回到了群居的时代。","tags":["Read"]},{"title":"Monash IT FIT5037","path":"/2024/04/19/Monash-IT-FIT5037/","content":"FIT5037Week 1: OverviewType of Network Attacks Interruption Availability Interception Confidentiality Modification Integrity Fabrication Authentication Security Goals Secrecy&#x2F; Confidentiality(CONF) Encryption Integrity Message Authentication Code(MAC) Digital Signature Authentication The digital signature, biometrics, password Non-repudiation(NR) The digital signature, biometrics Availability&lt;!–more–&gt; Week2 Cryptography Foundations for Network SecurityBlock cipher: process one input block at a time produce one output block for each input block common block sizes: 64, 128 and 256 bits Stream cipher: process input elements continuously produces one element at a time common element size: 1 bit or 1 byte operation is generally exclusive OR (XOR) between input elements and stream cipher key ECB, CBC,CFB, OFB, CTR RSA is not indistinguishable under chosen-cipher text attack Why are attacks in the IND-CPA model effective against RSA? Encryption can be performed by anyone. RSA encryption is deterministic. Probabilistic PKE AUTHentication + INTegrity: Diffie Hellman Key Exchange Digital Signature and MAC (Message Authentication Code) and HashDigital signatures reproduce the electronic version of the normal signatures proof of identity (authenticity of the message origin) proof of message integrity non-repudiation MAC Provides message integrity and authenticity MAC does not distinguish between two participants Hash One way function collision resistance Provides integrity check MAC Replay Attack and CountermeasureNonce + Challenge Response Protocol Countermeasure: Nonce Every time Bob wants to communicate, Alice sends a nonce (a challenge) to Bob. Then Bob calculates: Hash(key, “I’m Bob” || nonce). Alice receives the above hash value and recalculates it for verification. Since the hash value is different for each nonce, replay attacks are mitigated. Week3A: Public Key Infrastructure Authentication Confidentiality Integrity Non-repudiation Trust Digital SignaturesEncrypt message with private key -&gt; Generate digital signature Decrypt digital signature with public key -&gt; Verify digital signature -&gt; Check if M &#x3D;&#x3D; M’ How PKI Defeats the MITM AttackAlice needs to obtain a certificate from a trusted entity (Certificate Authority - CA). After verifying Alice’s identity, the trusted entity issues a certificate containing Alice’s name and publickey. Alice sends the entire certificate to Bob. Bob uses Alice’s public key to verify the certificate - ensuring it is from Alice and not someone else. The certificate cannot be forged or tampered with. Core Functions of a CASubject Verification Ensure that the entity applying for a certificate possesses or represents the identity in the subject field. Signing Digital Certificates The CA uses its private key to generate two digital signatures for the certificate. Once the signatures are applied, the certificate cannot be modified. Anyone with the CA’s public key can verify the signatures. Get a Certificate from CA:Step 1: Generate a public&#x2F;private key pair Step 2: Generate a certificate signing request (CSR); Attack Scenario: Genuine CertificateThe attacker forwards a genuine certificate to Alice. Alice recognizes the certificate as genuine, so she encrypts secret with the certificate’s public key andsends it to the “server.” The attacker intercepts the request but cannot decrypt the secret because they do not possess the privatekey. Attack Scenario: Fake CertificateThe attacker forges a certificate for the domain example.com using their own public key. The CA does not sign the certificate as the attacker is not associated with example.com. The attacker attempts to self-sign the certificate and sends it to Alice. Alice’s browser raises a warning as it cannot find any trusted certificate to validate the receivedcertificate. Attack Scenario: Attacker’s CertificateThe attacker possesses a valid certificate of their own. The attacker sends their certificate to Alice. Alice’s browser checks if the subject field of the certificate matches Alice’s intent. The received certificate’s validity is checked. The certificate’s subject (common name) is verified to match the server’s hostname. Attacks Against PKIMan-in-the-Middle Proxy The proxy creates a self-signed CA certificate installed on the user’s browser. The proxy intercepts communications. Attacks on CA Verification Process Attack on CA Signing Process: Private key compromise. How to protect private keys: Use a hardware security model. Attacks on Algorithms: Digital certificates rely on one-way hash and digital signatures. Use stronger algorithms. User Confirmation Attacks: Certain software does not compare the information within the certificate (commonname field) with the user-provided or approved information: Security vulnerability in Common Name. Week 3B: Email Security What are the main services provided by PGP? Key management, confidentiality, integrity, authenticity. What is the purpose of detached signatures? Signatures are sent separately. Two files: the original data and the signature. Why is R64 encoding used for email applications? Some email servers do not accept binary emails and require printable characters. R64 uses ASCIIcharacters, all of which are printable. What is S&#x2F;MIME? What encryption functions does S&#x2F;MIME use? S&#x2F;MIME &#x3D; Secure MIME 3DES&#x2F;AES for encryption, Elgamal for key exchange, SHA for signing What is DKIM? How does DKIM email authentication service differ from S&#x2F;MIME or PGP? The sender’s email server signs the email. DKIM is used for email server to email server communication, while PGP and S&#x2F;MIME are end-to-endencryption. Why is Transport Layer Security (TLS) not sufficient to protect email? Answer: TLS protects communication between two hops; all intermediate hops see plaintext. Simple Mail Transfer Protocol (SMTP) Text-only Limited to ASCII characters Size limitations Command-only Issues No security - plaintext messages PGP (Pretty Good Privacy) Key management Authentication (AUTH) + Integrity (INT) Digital signatures (No-Repudiation) Confidentiality (CONF) Encryption: Symmetric encryption IDEA, 3DES-EDE, AES Public-key encryption RSA, Elgamal, Digital Signature Algorithm Hash MD5, SHA-1, SHA-2, SHA-512 Encryption steps: HASH(M) &#x3D;&gt; digest RSA(digest, private key) &#x3D;&gt; digital signature sig RSA is a public-key encryption method used for signing. digital signature sig || M &#x3D;&gt; certificate Compress(certificate) &#x3D;&gt; compressed certificate AES(session key, compressed certificate) &#x3D;&gt; encrypted compressed certificate (using symmetricencryption) RSA(session key, recipient’s public key) &#x3D;&gt; encrypt session key for non-peer-to-peer encryption of thesession key Another user can retrieve the session key of 128 bits using their private key Sent to the recipient: encrypted compressed certificate || encrypted session key Decryption steps: Retrieve the decryption session key using the private key &#x3D;&gt; session key Decrypt the compressed certificate using the session key &#x3D;&gt; compressed certificate Obtain M || digital signature by decompressing the data &#x3D;&gt; M || digital signature &#x3D;DeCompress(compressed certificate) Verify Hash(M) and Hash(M’) Hash(M’) &#x3D; Decrypt the digital signature using the sender’s public key. Compression: PGP uses ZIP compression algorithm after applying the signature and before encryption. Why is this order important? Signing: It is best to sign the original message before compression to ensure the signature is based onthe original message. Transmission: Compression saves on email transmission and file storage space. Encryption: Encrypting after compression can enhance encryption because compression reduces redundancy inthe message. Radix-64 Encoding Used for compatibility with email protocols Text &#x3D;&gt; Binary &#x3D;&gt; ASCII characters (every 6 bits &#x3D; 1 ASCII character) Key Management Send Key Identifiers (KeyID) instead of the full public key for bandwidth efficiency. Users can have multiple key pairs. Two types of keyrings need to be maintained: User’s own public&#x2F;private key pairs Store the encrypted private key instead of the plaintext private key. Public keys of other communication partners Store the public keys of other users indexed by their KeyID. Trust Model Does not rely on Certificate Authorities (CAs). Each user is their own CA. Users sign the keys of users they trust, forming a web of trust. If there is a chain of signatures leading to a trusted key, the trusted key is signed by other trusted keys. Restrictions Misuse Leakage No forward secrecy Public key exchange is required. Targeted attacks against PGP KeyID. May hinder useful functionalities such as search, spam filtering, and subject extraction. Lack of non-repudiation and authentication in compromised scenarios. What is S&#x2F;MIME? What encryption functions are used in S&#x2F;MIME? S&#x2F;MIME stands for Secure&#x2F;Multipurpose Internet Mail Extensions. Digital Signatures RSA Hash Functions MD5, SHA-1, SHA-2 Session Key Encryption Key Transport: RSA, ElGamal (asymmetric) Key Agreement: Diffie-Hellman (DH) Message Encryption (Symmetric) AES-128 Triple DES (T3-DES) MAC (Message Authentication Code) HMAC with SHA-1 Cipher Modes AES-GCM (Galois Counter Mode) AES-CCM (Counter with CBC-MAC) Multipurpose Internet Mail Extensions (MIME) MIME supports different types of content. X.509 v3 certificates Each client has a trusted CA certificate list. Own key pairs and certificates signed by trusted CAs. DomainKeys Identified Mail (DKIM) Outgoing emails from the sender’s domain must be signed using the sender domain’s secret key before leavingthe domain. Transparent to the user Mail Submission Agent (MSA) signs Mail Delivery Agent (MDA) verifies The recipient can verify the signature using the domain’s public key. The public key is stored in DNS servers, and the signature is attached. What is DKIM? How does DKIM email authentication service differ from S&#x2F;MIME or PGP? DKIM stands for DomainKeys Identified Mail. The sender’s email server signs the email. DKIM is used for authentication between email servers, whereas PGP and S&#x2F;MIME provide end-to-end encryption. Q: Why don’t email service providers deploy end-to-end (user-to-user) email encryption?Encryption prohibits email systems from providing useful functionalities such as filtering, topic extraction,targeting ads, and search. Week4：IPSecVirtual Private Network (VPN) Isolation Tunneling Multiple logical overlay networks coexist on the same physical network, each network providing its ownprivate services. AnswerPlacing the VPN server in front of the firewall is better. VPN also has the functionality of a firewall. Afterthe VPN gateway, the messages will be decrypted, allowing the firewall to inspect the details of the packets. IPsec: Internet Protocol SecurityIPSec is a security protocol used to protect network layer data. It provides security processing at theInternet layer for IP datagrams, protecting them according to the security policies of the communicating IPnodes before forwarding them to the network interface layer. The receiving IP node verifies the datagrams based on established security parameters and rejects those thatare not protected according to the defined policies. The services provided by IPSec include: Authentication, Integrity, Confidentiality, No-Repudiation (butdoes not hide identity). Authentication: Verifies the claimed identity of the data source, ensuring the authenticity of the sender. Integrity: Data Integrity Anti-Replay: It can detect tampering with and duplicate arrival of individual IP datagrams. Confidentiality: Protects data from unauthorized disclosure and provides limited trafficconfidentiality. It hides the source IP address, destination IP address, size of IP datagrams, andcommunication frequency. The entire process of IPsec consists of five steps: Initiation: Something needs to trigger the creation of our tunnel. For example, when we configure IPsec on arouter, we use an access list to tell the router which data to protect. When the router receives content thatmatches the access list, it initiates the IKE process. The tunnel can also be initiated manually. IKE Phase 1: We negotiate a security association to build the IKE Phase 1 tunnel (ISAKMP tunnel). IKE Phase 2: In the IKE Phase 1 tunnel, we build the IKE Phase 2 tunnel (IPsec tunnel). Data Transfer: We send user data through the IKE Phase 2 tunnel to protect the user data. Termination: The IPsec tunnel will terminate after a period of time when there is no user data to beprotected. IPSec has two main protocols: Authentication Header (AH): Integrity Data-Origin Authentication Anti-Replay Access Control No Confidentiality Encapsulating Security Payload (ESP): Integrity Data-Origin Authentication Anti-Replay Confidentiality ESP can provide only confidentiality (CONF), only authentication (AUTH), or both. IPSec has two modes: Encapsulation Mode Transport Mode: Inserts the IPsec header into the IP packet to protect the data. Host-to-host Tunnel Mode: Keeps the original packet and adds a new header. The ESP&#x2F;AH header follows the new IP header, while theoriginal IP packet remains unchanged. Gateway-to-gateway Anti-replay ServicesReplay: AUTH packet Case If the received sequence number is smaller than the size of the current window’s leftmost edge, discard thepacket. If the received sequence number is within the range of the current window, check if the packet has beenreceived. If the received sequence number is greater than the maximum size of the current window, set the receivedsequence number as the maximum edge and calculate the minimum edge using N-W+1. If the recipient sets N&#x3D;60 and window size W&#x3D;64, the range should be 0-60. The IPSec policy file contains a list of entries:3 IPSec Policies: DISCARD Discard the packet. PROTECT Protect the packet using AH and ESP security protocols. BYPASS Bypass IPSec processing. Security Association (SA)SA is a contract between two entities that specifies how they will communicate using security services. Security Association Database (SAD) AH information ESP information SA lifecycle IPSec protocol mode (Transport&#x2F;Tunnel) IPSec Architecture Authentication Header (AH): Extended header for message authentication. Encapsulating Security Payload (ESP): Provides encryption with combined confidentiality and messageintegrity. Internet Key Exchange (IKE): Key management scheme for IPSec. SA establishment: Participants of the IKE protocol first establish security associations to define thesecurity parameters for the IPSec session, such as encryption algorithms, authentication algorithms, keylengths, etc. These parameters will be used for encrypting and authenticating IP packets. Key exchange: IKE uses the Diffie-Hellman key exchange algorithm to negotiate and generate shared keys.Through Diffie-Hellman key exchange, communicating parties can securely generate shared keys without directlytransmitting the keys. Authentication: The IKE protocol supports various authentication methods such as pre-shared keys,digital certificates, Public Key Infrastructure (PKI), etc. Authentication ensures that communicating partiescan mutually verify each other’s identities and prevent man-in-the-middle attacks. Key negotiation and establishment: Through the negotiation process, IKE parties use the Diffie-Hellmankey exchange algorithm to generate shared keys and use these keys to establish various keys required for theIPsec session, such as symmetric keys and asymmetric keys. Anonymising NetworkC. IPsec does not provide anonymity on the Internet. It is primarily used for encrypting and securing thetransmission of data, rather than hiding or anonymizing the identities of senders or receivers. Solution: decentralized, anonymous network A. When using Encapsulating Security Payload (ESP), it provides confidentiality. ESP is part of the IPsecprotocol suite and is used to provide encryption and authentication of data over IP networks. B. IPsec provides anti-replay properties, meaning it can prevent attackers from replaying captured packets,thus protecting the integrity and security of the communication. D. When using Authentication Header (AH), IPsec provides integrity. AH is also part of the IPsec protocolsuite, and it provides integrity and authentication of data but does not provide encryption. No CONF TOR Distributed Anonymous Communication ServiceThe sender must negotiate an encryption key with each router. Components of Tor Client Server Tor (Onion) router: Special proxy relays application data. Directory server: Provides Tor router information. Process The last router sees the plaintext data but doesn’t know where the message originated from. Each router only knows its predecessor and successor. Process of a client sending a message: The client retrieves the Tor node list from the directory server. The client randomly selects a path to the destination server. The client negotiates an AES key with each router (each router has its own encryption key). The client encrypts the message: C3 &#x3D; Encrypt(K3, data||IP_Server) C2 &#x3D; Encrypt(K2, C3 || IP_OR3) C1 &#x3D; Encrypt(K1, C2 || IP_OR2) The client sends an IP packet: IP_Client || IP_OR1 || C1 Packet processing at each router: Packet arrives at OR1: C2 || IP_OR2 &#x3D; DEC(K1, C1) Cache IP_Client, IP_OR2 Send an IP packet: IP_OR1 || IP_OR2 || C2 Packet arrives at OR2: C3 || IP_OR3 &#x3D; DEC(K2, C2) Cache IP_OR1 || IP_OR3 Send an IP packet: IP_OR2 || IP_OR3 || C3 Packet arrives at OR3: IP_Server || data &#x3D; DEC(K3, C3) Cache IP_OR2, IP_Server Send an IP packet: IP_OR3 || IP_SERVER || data Week5A：FirewallRequirements of a firewall All the traffic between trust zones should pass through the firewall. Only authorized traffic, as defined by the security policy, should be allowed to pass through. The firewall itself must be immune to penetration, which implies using a hardened system with securedOperating Systems. Determines the direction in which requests may be initiated and are allowed to flow through the firewall. Ittells whether the traffic is “inbound” (From the network to the firewall) or vice-versa “outbound” Firewall Policy• User control: Controls access to the data based on the role of the user who is attempting to access it. Applied to usersinside the firewall perimeter.• Service control: Controls access by the type of service offered by the host. Applied on the basis of network address, theprotocol of connection and port numbers.• Direction control: Determines the direction in which requests may be initiated and are allowed to flow through the firewall. Ittells whether the traffic is “inbound” (From the network to firewall) or vice-versa “outbound” Firewall actions• Accepted: Allowed to enter the connected network&#x2F;host through the firewall.• Denied: Not permitted to enter the other side of firewall.• Rejected: Similar to “Denied”, but tells the source about this decision through ICMP packet. three types of firewalls:• Packet Filter Firewall• Stateful Firewall• Application&#x2F;Proxy Firewall Overview of TLSTransport Layer Security (TLS) provides a secure channel between two communicating applications. Integrity: Channel can detect any changes made to the data during transmission Authentication: At least one end of the channel needs to be authenticated, so the other end knows who itis talking to. Confidentiality: Nobody other than the two ends of the channel can see the actual content of the datatransmitted. TLS Layer • TLS sits between the Transport &amp; Application layer• Unprotected data is given to TLS by the Application layer• TLS handles encryption, decryption, and integrity check• TLS gives protected data to the Transport layer TLS HandshakeBefore a client and server can communicate securely, several things need to be set up first: Encryption algorithm and key MAC algorithm Algorithm for key exchange Data is transferred using records:fragmentation: ≤ 16KB Each record contains a header and a payload. Padding Oracle Attack The goal of a padding oracle attack is to compromise the confidentiality of encrypted data, especially in caseswhere block cipher modes (such as CBC mode) are used for encryption. In this mode, the plaintext data is divided into fixed-sized blocks and transmitted after encryption using akey. Each encrypted block is encrypted using the ciphertext of the previous block as the initialization vector(IV). The steps of a padding oracle attack are as follows: The attacker intercepts the encrypted ciphertext and selects a specific encrypted block to attack. The attacker modifies the last byte of that encrypted block and sends the modified ciphertext back to thedecrypting entity. When the decrypting entity attempts to decrypt the modified ciphertext, if the padding verification stepfails (for example, if the format of the padding bytes is incorrect), the decrypting entity will return anerror, indicating a padding verification failure. The attacker leverages the result of the padding verification failure to infer the true value of the lastbyte of the modified ciphertext block. This is because the padding verification step provides information aboutthe correctness of the padding bytes’ format. By continuously modifying the padding bytes until the paddingverification succeeds, the attacker can deduce the correct value of the padding bytes. By repeating the above steps byte by byte, the attacker can deduce the value of each byte in the encryptedblock in sequence. Countermeasures Remove server responses Use AES GCM model - authenticated encryption Ensure that the ciphertext is not modified during the transmission Week 5:Wireless NetworkWireless Network Security Overview and Countermeasures Wireless networks face various security threats, but there are countermeasures to mitigate these risks. The basic elements of the IEEE 802.11 wireless security standard include WEP (insecure), WPA, and WPA2. Understanding the vulnerabilities in the implementation of WPA2 and analyzing the unique threats posed byphysical layer interference attacks. Wireless Security: The Problem Channel: Broadcast nature makes it easier for eavesdropping and interference. Mobility and Accessibility: Mobile devices are more susceptible to threats. Resources: Limited memory&#x2F;power makes it challenging to implement robust security systems. The MAC address (Media Access Control Address) is a unique identifier for network interfaces used to identifydevices on a local network. However, MAC address-based authentication can be bypassed because MAC addresses canbe spoofed or forged. Attackers can use specific software or tools to modify their device’s MAC address, masquerading as a trusteddevice. This deception allows attackers to bypass MAC address-based authentication measures and gainunauthorized network access. Therefore, although the MAC address serves as a unique identifier for a device, it is not a reliableauthentication mechanism as it can be tampered with or forged. In wireless networks, higher-levelauthentication methods such as WPA&#x2F;WPA2 passwords, enterprise-level 802.1X authentication, etc., are typicallyrequired for stronger security. Threat： Man-in-the-Middle attack Identity theft, media access control(MAC) address spoofing Ad hoc networks Denial of Service(DoS) Network injection Wireless Security Measures Securing transmissions: signal-hiding: to protect the location of access points encryption Securing access points authentication JammingThe adversary interferes with the reception of messages by transmitting a continuous jamming signal, or severalshort jamming pulses. cause DoS Detection: monitor signal strength monitor carrier sensing time Week6：Network AttacksSecurity of WEP in IEEE 802.11b: Encryption Algorithm: WEP uses RC4 to encrypt data. RC4 is a stream cipher algorithm used to generateciphertext by XORing plaintext with a key. Key Management: WEP uses a fixed key for encryption, typically a 40-bit or 104-bit key. The key needs to beshared between the wireless access point and wireless clients. Insecurity Improved IV Management: Detection of IV reuse IV collisions WEP Recommendations: Changing IV for each data packet Some weak implementations of WEP Message modification without knowledge of the key Insecurity INT CRC32 is not a MAC: It is linear CRC32 used with stream cipher: Stream ciphers are linear Modification of ciphertext possible without disclosing m Insecurity of WEP in IEEE 802.11b: Key Weakness: WEP uses a relatively small key space of 40 bits or 104 bits, making it vulnerable toexhaustive attacks. Attackers can attempt all possible key combinations to break WEP encryption. Initialization Vector (IV) Reuse: WEP uses a 24-bit IV to increase encryption strength. However, WEP repeatsthe same IV in practical use, leading to repetitiveness in encrypted traffic, allowing attackers to retrievethe encryption key. Weaknesses in the RC4 Algorithm: The RC4 algorithm used by WEP has certain weaknesses that enable attackersto recover the key by analyzing the encrypted data stream. This type of attack is known as WEP key recoveryattack. Data Integrity Issues: WEP does not provide a mechanism for data integrity checks, which means attackers cantamper with the data without being detected. Key Management and Authentication Issues: WEP employs weak key management and authentication mechanisms,making it susceptible to dictionary attacks and forged authentication attacks. Security of WPA TKIP in IEEE 802.11gTemporal Key Integrity Protocol (TKIP) Key Mixing: IV and key are mixed before RC4 encryption for each packet. Protection against replay attacks using sequence counter. Message Integrity Check (MIC) instead of CRC32 for data integrity. Rekeying: Unique key for each packet. Security of WPA2 CCMP in IEEE 802.11i Authentication: Verifying the identity of users or devices. Confidentiality: Protecting data from being intercepted during transmission by encrypting it. Integrity: Ensuring that data is not tampered with during transmission using checksums and MessageAuthentication Codes (MAC). Difference between TKIP and CCMP: TKIP was introduced to enhance the security of WEP (Wired Equivalent Privacy). It provides encryption,integrity, and message authentication but is relatively weaker. CCMP is the encryption protocol used in WPA2, providing authentication, integrity, and confidentiality. It ismore secure than TKIP. WPA2 (PSK): Password Cracking Attack The attacker starts by monitoring the wireless network (using tools like Wireshark). The attacker identifies connected users on the WiFi (can be discovered using Wireshark). The attacker forges a de-auth packet and forces the victim user to disconnect from the WiFi. When the user reconnects to the WiFi, the attacker captures the handshake containing the PSK hash value. The attacker offline cracks the hash and recovers the password. WPA2: Security Best Practices Avoid WPA2 PSK. Use EAP-TLS certificate-based authentication. Implement rogue access point detection. Use the latest operating system. Network Layer: Lower Layers VPN (Virtual Private Network) and IPSEC (Internet Protocol Security): VPN and IPSEC are excellent when you want to encrypt all network traffic. Transport Layer: TLS (Transport Layer Security): Services provided: Confidentiality: Protects data from being intercepted during transmission through encryption. Encryption: Data is encrypted using cryptographic algorithms, ensuring only authorized parties can decrypt it. - Integrity: Ensures data is not tampered with during transmission through checksums and MessageAuthentication Codes (MAC). - Message Authentication Code (MAC): Used to verify the integrity and authenticity of messages. - Authentication: Verifies the identity of communicating parties through methods like digitalcertificates. Application Layer: SYN Flood Attack: SYN flood attacks exploit vulnerabilities in the TCP three-way handshake process. Attackers continuouslysend a large number of forged SYN packets to servers, depleting the server’s Transmission Control Block (TCB)queue resources. Countermeasure: SYN Cookie Upon receiving a SYN packet, the server calculates a keyed hash using a key derived from the SYN packet. The hash value (H), known as the SYN cookie, is sent to the client (IP address) as the initial sequence number. - The server does not store half-open connections in its queue. - Since the attacker receives a fake IP address, they won’t receive H. - Legitimate clients send H+1 to the server, which the server verifies.2. TCP RST Attack: - TCP RST attacks involve immediately terminating a connection between two hosts by sending RST packets. - TLS cannot prevent TCP RST attacks since TLS operates above TCP and cannot protect the TCP header,allowing the RST flag to be set. - Solution: Use Intrusion Detection Systems (IDS) to detect and prevent TCP RST attacks.3. TCP Session Hijacking Attack: - Hackers can execute TCP session hijacking attacks by capturing packets and manipulating the next sequencenumber and acknowledgement number. - Solution: - Make it difficult to spoof packets by randomizing initial sequence numbers and source port numbers. - Encrypt the TCP payload. DNS Protocol: Authoritative Name Server (Domain Name System): Each DNS zone has at least one authoritative name server responsible for publishing information aboutthat zone and providing authoritative and deterministic responses to DNS queries. Local DNS Cache Poisoning Attack: Attack against user machines: Attackers send forged DNS responses with malicious IP addresses to usermachines that send DNS queries. Attack against local DNS servers (cache poisoning attack): Attackers send forged responses to local DNSservers while they perform iterative queries to DNS servers on the Internet, as long as they arrive before theactual responses. Remote DNS Cache Poisoning Attack: Remote DNS cache poisoning attack requires guessing port numbers, transaction IDs, etc. Cache impact: If no attempts fail, the actual response will be cached by the local DNS server, and theattacker needs to wait for cache timeout to make the next attempt. Countermeasures: DNSSEC (DNS Security Extensions): DNSSEC provides authentication and integrity checks for DNS data but does not provide confidentialityprotection. All answers from DNSSEC-protected zones are digitally signed. TLS&#x2F;SSL: Client and server negotiate encryption algorithms and session keys. Relies on trust and decisions regarding certificate authorities for key issuance. HTTPS is built on top of TLS&#x2F;SSL, defeating DNS cache poisoning attacks. Countermeasure for Kaminsky DNS Cache Poisoning Attack:b. Use DNSSEC c. Randomize source port numbers Week7A：IDSIntruders: Impersonator: Typically refers to someone who attacks a system from the outside. Insider: Typically refers to someone who attacks a system from within. Covert Operator: Can be either an external or internal attacker. Design Objectives: Detect various types of intrusion behavior. Including known and unknown attacks. Adapt to new attacks or changes in behavior. Real-time detection of intrusion behavior. Efficient analysis of user activity. Timely reporting of suspicious incidents. Ensure accuracy. Minimize false positives and false negatives. IDS Models: Signature-based: Unusual behavior is known. Alerts are generated when activity matches a signature. Anomaly-based: Normal behavior is known. Alerts are generated when activity deviates from normal behavior. Requires more time and processing power. Can produce false positives (normal activity identified as malicious) and false negatives (malicious activityconsidered normal). Threshold Anomaly Detection Statistical Anomaly Detection Heuristic-based: Uses machine learning models of normal behavior. Alerts are generated when the model identifies activity as anomalous. IDS Architecture: Auditor: Records all security-related activities for analysis. Analyzer: Analyzes data from the auditor automatically and updates settings as needed. Notifier: Reports detected anomalies and updates settings as needed, triggers appropriate countermeasures. IDS Types: Host-based IDS (HIDS): Deployed on individual systems to detect malicious activity on a single device. Can also be used in adistributed system within a network. Pros: Lower cost, as most HIDS are software-based; visibility into low-level activities; lower falsepositive rates for local threats. Cons: Limited view of the network; potential for system tampering by malicious insiders. Network-based IDS (NIDS): Monitors network traffic to detect intrusion behavior across the entire network. Pros: Can see attacks in network traffic, particularly at the transport or IP layer; difficult to tamperwith. Cons: May require dedicated hardware; challenging to inspect encrypted traffic. Week7B：Denial of service attackGoals Target on availability take out a large site with little computing work How: amplification DoS bug -&gt; design flaw DoS flood -&gt; command bot-net to generate a flood of requests Will bypass SYN flood protection proxy Mitigation Client puzzles given challenges for TCP connection floods, the first data must contain a puzzle solution, otherwise, the TCP connectionis closed. for SSL handshake DoS Challenge C based on TLS session ID Server: check puzzle solution before RSA decryption Limitations Requires changes to both clients and servers Hurts low-power legitimate clients during an attack CAPTCHAs Applies to application layer DDoS Source identification Ingress filtering identify packet source block the attack at the source ISP only forwards packets with legitimate source IP Source identification Traceback DDoS involves many packets on thes ame path Store one link in each packet Path can be long Countermeasures Prevent initial hack Use of firewalls Check ingress&#x2F;egress packets Use a server farm and load balancer to offset the effects of a DDoS attack Change the IP address of the attacked system Week8：Penetration Testing in PracticeTypes of tests: **Application penetration testing (**typically web applications), which finds technical vulnerabilities Infrastructure penetration testing, which examines servers, firewalls and other hardware for securityvulnerabilities. TIPSMAC Only Authenticity Integrity IEEE 802.11i Security of WPA2 CCMP Authentication: Verifying the identity of users or devices. Confidentiality: Protecting data from being intercepted during transmission by encrypting it. Integrity: Ensuring that data is not tampered with during transmission using checksums and MessageAuthentication Codes (MAC). Transport Layer Security (TLS): Confidentiality: Protecting data from being intercepted during transmission by encrypting it. Integrity: Ensuring that data is not tampered with during transmission using checksums and MessageAuthentication Codes (MAC). Authentication: Verifying the identity of communication parties through methods like digital certificates.","tags":["Monash"]}]