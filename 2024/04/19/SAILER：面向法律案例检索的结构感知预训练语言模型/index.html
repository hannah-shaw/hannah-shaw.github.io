
<!DOCTYPE html><html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.27.0" theme-name="Stellar" theme-version="1.27.0">
  
  <meta name="generator" content="Hexo 7.2.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f9fafb">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  
  <title>SAILER：面向法律案例检索的结构感知预训练语言模型 - Hannah_Shaw</title>

  
    <meta name="description" content="SAILER：面向法律案例检索的结构感知预训练语言模型SAILER: Structure-awarePre-trained Language Model for Legal Case Retrieval Author: Tsinghua UniversityType: Academic JournalPublisher: SIGIR 2023 摘要法律案件检索旨在为查询案件找到相关案件，在智能法律">
<meta property="og:type" content="article">
<meta property="og:title" content="SAILER：面向法律案例检索的结构感知预训练语言模型">
<meta property="og:url" content="http://example.com/2024/04/19/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Hannah_Shaw">
<meta property="og:description" content="SAILER：面向法律案例检索的结构感知预训练语言模型SAILER: Structure-awarePre-trained Language Model for Legal Case Retrieval Author: Tsinghua UniversityType: Academic JournalPublisher: SIGIR 2023 摘要法律案件检索旨在为查询案件找到相关案件，在智能法律">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%201.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%202.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%203.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%204.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%205.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%206.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%207.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%208.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%209.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2010.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2011.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2012.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2013.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2014.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2015.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2016.png">
<meta property="og:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2017.png">
<meta property="article:published_time" content="2024-04-18T18:28:16.000Z">
<meta property="article:modified_time" content="2024-04-18T18:29:14.066Z">
<meta property="article:author" content="Hannah">
<meta property="article:tag" content="papers">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled.png">
  
  
  
  <meta name="keywords" content="papers">

  <!-- feed -->
  

  <link rel="stylesheet" href="/css/main.css?v=1.27.0">

  

  

  
</head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://pic.aigexing.net/uploads/9/1253/1608374577/93536629702/28776239.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Hannah_Shaw</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="Search"></form><div id="search-result"></div><div class="search-no-result">No Results!</div></div>


<nav class="menu dis-select"></nav>
</div>
<div class="widgets">


<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">Recent Update</span></div><div class="widget-body fs14"><a class="item title" href="/2024/04/19/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"><span class="title">SAILER：面向法律案例检索的结构感知预训练语言模型</span></a><a class="item title" href="/2024/04/19/CaseEncoder-%E7%94%A8%E4%BA%8E%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E7%BC%96%E7%A0%81%E7%9A%84%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><span class="title">CaseEncoder_用于法律案例编码的知识增强预训练模型</span></a><a class="item title" href="/2024/04/19/%E5%80%A6%E6%80%A0%E7%A4%BE%E4%BC%9A/"><span class="title">倦怠社会</span></a><a class="item title" href="/2024/04/19/Monash-IT-FIT5037/"><span class="title">Monash IT FIT5037</span></a></div></widget>
</div>

</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">Home</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">Blog</a></div>
<div class="flex-row" id="post-meta"><span class="text created">Posted on: <time datetime="2024-04-18T18:28:16.000Z">2024-04-19</time></span><span class="sep updated"></span><span class="text updated">Updated on: <time datetime="2024-04-18T18:29:14.066Z">2024-04-19</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>SAILER：面向法律案例检索的结构感知预训练语言模型</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><h1 id="SAILER：面向法律案例检索的结构感知预训练语言模型SAILER-Structure-aware"><a href="#SAILER：面向法律案例检索的结构感知预训练语言模型SAILER-Structure-aware" class="headerlink" title="SAILER：面向法律案例检索的结构感知预训练语言模型SAILER: Structure-aware"></a>SAILER：面向法律案例检索的结构感知预训练语言模型SAILER: Structure-aware</h1><p>Pre-trained Language Model for Legal Case Retrieval</p>
<p>Author: Tsinghua University<br>Type: Academic Journal<br>Publisher: SIGIR 2023</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>法律案件检索旨在为查询案件找到相关案件，在智能法律系统中发挥着核心作用。尽管预训练在临时检索任务中取得了成功，但有效的法律案例检索预训练策略仍有待探索。与一般文档相比，法律案例文档通常是具有内在逻辑结构的长文本序列。然而，大多数现有的语言模型很难理解不同结构之间的长距离依赖关系。此外，与一般检索相比，法律领域的相关性对关键法律要素很敏感。即使关键法律要素上的细微差别也会显着影响相关性的判断。然而，现有的为通用目的而设计的预训练语言模型尚不具备处理法律要素的能力。</p>
<p>为了解决这些问题，在本文中，我们提出了<br>SAILER，一种用于法律案例检索的新的结构感知预训练语言模型。突出表现在以下三个方面：（1）SAILER充分利用法律案例文件中包含的结构信息，更加关注关键的法律要素，类似于法律专家浏览法律案例文件的方式。(2)<br>SAILER采用非对称编码器-解码器架构来集成多个不同的预训练目标。通过这种方式，跨任务的丰富语义信息被编码成密集向量。（3）SAILER即使在没有任何法律标注数据的情况下也具有强大的判别能力。能够准确区分不同罪名的法律案件。对公开可用的法律基准进行的广泛实验表明，我们的方法在法律案例检索方面可以显着优于以前最先进的方法</p>
<p><strong>表<br>1：介绍法律相关性的示例。这两段文字非常相似，但由于关键的法律要素，在法律上不相关。</strong> </p>
<p>A段：X人，24岁，男性，身高180厘米。<br>2018年，他5次进入商场，盗窃手机一部、平板电脑两台，价值1000万。五点钟，他回到家，将上述物品交给Y人。</p>
<p>B款：X人，24岁，男性，身高180厘米。<br>2018年，他5次进入商场，购买了一部手机、两台平板电脑，总价值1000万。五点钟，他回到家，将上述物品交给Y人。</p>
<p><strong>引言</strong></p>
<p>法律案例检索在现代法律体系中起着重要作用。为了实现正义和公平，在法律专家做出判决之前，找到并分析特定案例的相关先例是必要的。近年来，随着法律案例文件数量的激增，在整个语料库中找到相关案例变得越来越具有挑战性。因此，法律案例检索系统的研究受到法律和信息检索社区的重视[2,<br>3, 24, 31,<br>38]。在特定领域（如法律案例检索）中，构建高质量的带注释数据集通常需要大量的人力和领域专业知识，因此具有禁锢性。然而，最先进的检索系统通常基于使用大规模带注释数据进行训练的神经模型构建而成。因此，信息检索研究人员提议利用预训练语言模型（PLM），即在语言理解方面无需监督数据进行训练的大规模神经模型，来进行有效的检索[13,<br>17, 36, 43]。先前的研究[7, 10, 16, 42]表明，诸如BERT [9] 和RoBERTa [18]<br>等PLM在段落和文档检索数据集（如MS MARCO和TREC<br>DL）上在零样本和少样本设置下明显优于现有的神经检索模型[8, 25,<br>35]。尽管它们在临时检索和开放领域搜索中的性能优越，但是预训练语言模型在法律案例检索中的有效性尚未观察到。与传统检索任务相比，PLM应用于法律案例检索呈现出两个被现有研究忽视的非平凡挑战[31]。</p>
<p>挑战1：法律案例文件通常是具有固有写作逻辑的长文本序列。如图1所示，在案例法律系统和法令法律系统中，案例文件通常包括五个部分：程序、事实、推理、决定和尾部（我们将在第3节讨论这些部分的细节）。每个部分代表一个特定主题，字数从数百到数千不等。这些部分以标准法律逻辑编写，通常彼此相关。现有的PLM要么具有有限的文本建模能力，阻碍了其对长文档的建模能力[9,<br>18]，要么忽视了法律案例文件的结构，使其无法捕捉法律写作逻辑中的远距离依赖关系[34]。因此，基于普通PLM的检索器的性能受到限制。</p>
<p>挑战2：法律领域中的相关概念与一般搜索中的概念有很大不同。在法律案例检索中，两个法律案例之间的相关性对其关键法律要素（例如“强行占用他人财产”，“任意毁坏他人财物”等）敏感。这里的关键法律要素包括关键情节和关键情节或因素的法律概念抽象[24]。没有关键法律要素或具有不同关键法律要素的案例可能导致不同的判决。例如，如表1所示，在临时检索中，这两段通常被认为是相关的，因为它们共享大量关键词和句子。然而，在法律案例检索中，这两段是不相关的，并且由于关键法律要素的影响可能导致完全不同的判决。在没有指导的情况下，开放领域PLM-based神经检索模型难以理解关键法律要素，在法律领域中的检索性能不佳。</p>
<p>为了应对这些挑战，我们提出了一种面向法律案例检索的结构感知预训练语言模型（SAILER）。SAILER采用编码器-解码器架构明确地对法律案例文件的事实和其他部分之间的依赖关系进行建模和捕捉（挑战1）。同时，SAILER利用推理和决定段落中的法律知识来增强对关键法律要素的理解（挑战2）。具体而言，我们使用深度编码器将事实段落编码为密集向量。然后，在事实向量的帮助下，分别将两个浅解码器应用于推理和决定段落中的被大幅屏蔽的文本的重构。</p>
<p>这样，SAILER充分利用了法律案例文件中的逻辑关系和不同结构中的知识。为验证我们方法的有效性，我们在中文和英文法律基准测试中进行了大量实验。实证实验结果表明，SAILER相对于最先进的基线模型可以取得显著改进。我们总结本文的主要贡献如下：</p>
<p>(1)<br>我们提出了一个针对法律案例检索的新型预训练框架，即SAILER，这是首个利用法律案例结构进行预训练的工作。</p>
<p>(2)<br>我们提出了几种预训练目标，通过模拟法律案例文件的撰写过程，捕捉不同结构之间的长距离文本依赖关系和内在的写作逻辑知识。</p>
<p>(3)<br>我们对公开的中文和英文法律基准进行了大量实验。实验结果表明，在法律案例检索中建模长距离文本依赖和利用结构知识的益处。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled.png" alt="Untitled"></p>
<p>图<br>1：法律案例结构图解。左案例来自美国（判例法体系），右案例来自中国（成文法体系）。标准法律案例文件可分为五个部分：程序、事实、推理、决定和尾部。</p>
<h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h1><h2 id="2-1-针对密集检索的预训练语言模型"><a href="#2-1-针对密集检索的预训练语言模型" class="headerlink" title="2.1 针对密集检索的预训练语言模型"></a>2.1 针对密集检索的预训练语言模型</h2><p>密集检索（DR）通常使用双编码器分别对查询和文档进行编码，并通过简单的相似性函数（余弦或点积）计算相关性得分。许多研究者通过负采样和蒸馏进一步提高了密集检索的性能[6,<br>12, 26, 37,<br>42]。信息检索领域的研究者已经开始设计针对密集检索的预训练方法[14, 15, 19,<br>21, 22, 32,<br>33]。这些方法主要旨在更好地表示带有[CLS]嵌入的上下文语义。它们基于[CLS]嵌入应编码给定文本中的重要信息以实现稳健匹配的直觉。例如，Condenser<br>[14] 和 coCondenser [15]<br>在编码器的最后层设计跳跃连接，以强制将信息聚合到[CLS]标记中。最近，基于自编码器的预训练引起了广泛关注。输入句子被编码为嵌入以重构原始句子，强迫编码器生成更好的句子表示。SEED-Encoder<br>[21] 提议使用弱解码器进行重构。SIMIM [32] 和 RetroMAE [19]<br>修改解码方法以加强信息瓶颈，从而提高生成嵌入的质量。</p>
<p>尽管取得了成功，基于自编码器的模型无法充分理解法律案例文件中不同结构之间的逻辑关系，因为它们主要依赖语料库中有限的信息。此外，由于案例文本包含许多对判断案例相关性不重要的事实，重构原始文本可能降低密集向量的区分力。</p>
<h2 id="2-2-法律案例检索"><a href="#2-2-法律案例检索" class="headerlink" title="2.2 法律案例检索"></a>2.2 法律案例检索</h2><p>法律案例检索模型主要分为两大类[3]：基于专家知识的模型[30, 39]<br>和自然语言处理（NLP）模型[5, 23, 31,<br>34]。对于基于专家知识的模型，Zeng等人[39]扩展了传统法律问题元素，并引入了一组新的子元素用于表示法律案例。随着深度学习的发展，基于NLP的模型在法律案例检索中取得了巨大成功。Shao等人[31]将法律案例文本划分为若干段落，并使用BERT获取段落之间的相似度，实现了有前景的排名性能。Paheli<br>Bhattacharya等人[4]结合文本和网络信息来估计法律案例的相似性。近年来，许多研究者尝试设计预训练技术以在法律领域获得性能提升。例如，Chalkidis等人[5]从多个领域（如立法、法院案例、合同）收集了大量英文法律文本，并发布了LEGAL-BERT。Xiao等人[34]提出了针对较长法律文本的Lawformer，可以处理数千个标记的文档。然而，它们都没有针对法律案例检索设计预训练目标。我们认为，预训练模型的潜力尚未充分挖掘。</p>
<h1 id="3-背景和基础知识"><a href="#3-背景和基础知识" class="headerlink" title="3 背景和基础知识"></a>3 背景和基础知识</h1><p>在本节中，我们介绍法律案例检索的问题定义以及有关法律案例文档的初步知识。</p>
<h2 id="3-1-问题阐述"><a href="#3-1-问题阐述" class="headerlink" title="3.1 问题阐述"></a>3.1 问题阐述</h2><p>法律案例检索任务指的是从候选案例集中找到与给定查询案例相关的案例。形式上，给定一个查询案例<br>𝑞 和一个候选案例集合 D，任务是从大型候选池中检索出前 𝑘 个相关案例 D𝑞 &#x3D;<br>𝑑∗ 1,𝑑∗ 2, ……, 𝑑∗<br>𝑘。为简单起见，我们专注于一种被广泛用于检索任务的双编码器架构[16,<br>42]。该架构包括一个查询编码器和一个文档编码器，其主要目标是将文本映射到高维嵌入<br>ℎ𝑞 和<br>ℎ𝑑。在这里，文档编码器和查询编码器通常使用预训练语言模型进行实现或初始化，该模型通过接受原始文本作为输入产生嵌入表示（例如，[CLS]<br>标记的嵌入）。然后，使用点积计算 𝑞 和 𝑑 的语义相关分数：𝑆 (𝑞, 𝑑) &#x3D;<br>ℎ𝑞 · ℎ𝑑 (1)</p>
<p>如图1所示，候选案例包括事实 𝐹，推理 𝑅，决定 𝐷<br>等部分。在大多数实际的法律案例检索场景中，查询 𝑞 仅包含基本的事实<br>𝐹，而候选案例则是完整的案例文档。特别是，根据查询案例的基本事实，律师或法官使用法律案例检索系统寻找与查询案例相关的案例，以便更好地完成其下游任务，例如司法判决。在我们的工作中，我们遵循上述设置，并假设查询是法律案例文档的基本事实。</p>
<h2 id="3-2-初步知识"><a href="#3-2-初步知识" class="headerlink" title="3.2 初步知识"></a>3.2 初步知识</h2><p>与 Web<br>搜索等开放领域检索任务中的文档相比，法律案例文档通常具有更清晰但更复杂的结构。具体来说，在具有案例法律系统的国家，例如美国，法律案例文档通常包括程序、事实、推理、决定和尾部。程序部分介绍了当事人信息和诉讼状况。事实部分描述了当事人的论点、证据和基本事件。推理部分是法院选择规则并将其应用于事实的过程。在推理部分，法官解释了应用规则的原因。换句话说，在这个部分中反复提到与规则应用相关的事件，即关键法律要素。决定部分是法院基于案件关键事实给出的具体回应。推理部分和事实部分是法院决定的基础。尾部部分介绍了法院、法官等的基本信息。在具有法令法律系统的国家，如中国，法律案例文档具有相同的结构，但没有明确分成不同的部分。中国法律案例文档的结构是通过文本格式传达的。例如，“经审查”通常是事实部分的开头，“法院认为”之后通常是推理部分。尽管不同国家之间的法律制度和条款存在差异，但这些部分是完整法律案例文档的共同基础。</p>
<p>在实际审判中，编写法律文件的过程如图2所示。首先，原告的论点、被告的论点和它们的证据被呈现给法庭。法官们将其总结形成事实部分。然后，法官们确定与事实相匹配的法律和与事实相关的案例。在此之后，法官们提取关键法律要素，并根据这些要素解释法律的适用情况，以形成推理部分。最后，基于他们对案例和法律知识的理解，法官们做出最终的司法决定，例如诉因、处罚期限、赔偿金额等。在上述过程中，事实部分的重要信息将在推理部分中进行仔细分析，这将影响最终的决定。事实、推理和决定之间的这种逻辑连接对于理解和建模法律案例文档非常重要，这启发了我们提出针对法律案例检索的结构感知预训练语言模型。关于我们提出的方法的更多细节将在下一节中描述。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%201.png" alt="Untitled"></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%202.png" alt="Untitled"></p>
<h1 id="4-方法"><a href="#4-方法" class="headerlink" title="4 方法"></a>4 方法</h1><p>在本节中，我们详细描述了针对法律案例检索的结构感知预训练语言模型。为了将结构知识整合到语言模型中，我们模拟了法律案例文件的撰写过程，并提出了<br>SAILER，如图3所示。SAILER<br>主要由三个组件组成，即事实编码器、推理解码器和决定解码器。具体来说，在预训练过程中，我们使用类似于<br>BERT<br>的编码器来生成事实的向量表示，然后使用两个浅层解码器来重构推理和决定部分的文本。关于<br>SAILER 的详细描述如下。</p>
<h2 id="4-1-事实编码器"><a href="#4-1-事实编码器" class="headerlink" title="4.1 事实编码器"></a>4.1 事实编码器</h2><p>在事实编码器中，我们首先随机用特殊标记 [MASK]<br>替换事实的一些标记。只有少量的标记被替换，因为大多数事实需要被保留。特别地，我们将事实定义为<br>𝐹 &#x3D; [𝑓1, 𝑓2, …, 𝑓𝑛]，掩码标记集定义为 𝑚(𝐹 )，其中 𝑓 表示标记，𝑛<br>表示事实的长度。因此，其余标记可以表示为 𝐹 \𝑚(𝐹 )。然后，被掩码的输入<br>𝐹𝑚𝑎𝑠𝑘 被事实编码器 𝜙𝐹 (·) 转换为一个句向量。类似于之前的工作[9,<br>14]，[CLS] 标记的最终隐藏状态被作为整个句子的表示：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%203.png" alt="Untitled"></p>
<p>与 Bert 类似，我们将被掩码的事实输入编码器以恢复 𝑚(𝐹 )<br>并计算掩码语言建模（MLM）损失作为我们预训练目标之一。具体来说，MLM 损失<br>𝐿𝑀𝐿𝑀 定义如下</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%204.png" alt="Untitled"></p>
<h2 id="4-2-推理解码器"><a href="#4-2-推理解码器" class="headerlink" title="4.2 推理解码器"></a>4.2 推理解码器</h2><p>如上所述，推理部分包含案例的所有关键法律要素。因此，我们设计了推理解码器来模拟推理和事实之间的逻辑关系，旨在提高编码器关注点与案例文件中潜在关键法律要素之间的对齐度。具体来说，我们通过扰乱推理部分原始文本<br>𝑅 &#x3D; [𝑟1, 𝑟2, …, 𝑟𝑛]<br>来构建推理解码器。我们将推理文本分割为标记，并随机选择一个子集 𝑚(𝑅)<br>进行掩码。采用了激进的掩码比例（30%-60%）用于语言重构。此外，密集向量 ℎ𝐹<br>替换了原始的 [CLS]<br>向量，通常用作解码器输入的起始部分。整个解码器输入被形式化为：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%205.png" alt="Untitled"></p>
<p>其中 erk 和 prk 表示 rk<br>的嵌入和额外位置嵌入。这样，推理解码器的学习目标可以表述为：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%206.png" alt="Untitled"></p>
<p>推理解码器需要依赖于 ℎ𝐹 来恢复被掩码的推理部分，这迫使 ℎ𝐹<br>专注于与事实中推理部分相关的有用信息。通过这种设计，SAILER增强了对关键法律要素的关注，并捕获了事实和推理之间的长期依赖关系。</p>
<h2 id="4-3-决定解码器"><a href="#4-3-决定解码器" class="headerlink" title="4.3 决定解码器"></a>4.3 决定解码器</h2><p>法律判决预测（LJP）旨在基于事实描述预测案件的判决结果[11]。如果两个案例具有相同的指控和法律条文，那么它们在向量空间中的密集向量应该更加接近。在这部分中，法律判决预测被建模为一个文本到文本的任务，使用决定解码器来帮助向量具有更强的区分能力。对于中国的法律案例，决定通常包括相关的法律条文、指控和处罚条款。给定一个决定部分<br>𝐷 &#x3D; [𝑑1, 𝑑2, …,<br>𝑑𝑛]，我们根据其指定的格式对其进行掩码。具体而言，决定通常格式化如下：根据中华人民共和国刑法【𝑧1】，被告犯有【𝑧2】罪，并被判【𝑧3】，其中<br>𝑧1 表示具体的法律条文，𝑧2 表示指控，𝑧3 是处罚期限。我们使用 Z<br>来表示所有被掩码的标记。在一些决定部分没有特定格式的国家，我们选择一定比例的具有高<br>TF-IDF [1] 值的词语进行掩码。为方便起见，我们仍然将被掩码的标记称为<br>Z。决定解码器也依赖于密集向量 ℎ𝐹<br>来恢复原始的决定。具体来说，决定解码器的输入是：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%207.png" alt="Untitled"></p>
<p>其中 edk 和 pdk 表示 dk 的嵌入和额外位置嵌入。决策解码器的训练目标是：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%208.png" alt="Untitled"></p>
<p>简而言之，决策解码器巧妙地对法律判决预测任务进行建模，以帮助生成判别向量。 </p>
<h2 id="4-4-学习"><a href="#4-4-学习" class="headerlink" title="4.4 学习"></a>4.4 学习</h2><p>在预训练过程中，我们旨在优化以下训练目标：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%209.png" alt="Untitled"></p>
<p>在预训练完成后，我们丢弃了两个解码器并对编码器进行了微调。微调的目的是使查询在向量空间中与相关案例相比较于不相关案例更接近。因此，给定查询案例<br>𝑞，假设 𝑑+ 和 𝑑 − 分别为相关和负面案例，损失函数 𝐿 定义如下：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2010.png" alt="Untitled"></p>
<p>遵循先前的工作 [26, 41]，负样本 𝑑 − 是 BM25<br>的硬负样本。在训练过程中，对于每个查询案例采样许多负样本计算上是很昂贵的。因此，我们采用批内负样本<br>[16]<br>进行对比学习，以充分利用同一批次中的负样本。具体来说，如果一个批次中有 𝐵<br>个查询，每个查询具有一个正样本和 𝑁<br>个负样本，那么在训练期间，对于每个查询我们最多可以获得 (𝐵 − 1) ∗ (𝑁 + </p>
<ol>
<li>个批内负样本。</li>
</ol>
<h1 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a>5 实验</h1><p>在本节中，我们首先介绍了我们的实验设置，包括数据集和指标、基线和实现细节。然后，我们报告了实验结果来证明<br>SAILER 的有效性。</p>
<h2 id="5-1-数据集和指标"><a href="#5-1-数据集和指标" class="headerlink" title="5.1 数据集和指标"></a>5.1 数据集和指标</h2><p>我们在四个法律案例检索基准上进行了实验。统计数据如表2所示。</p>
<ul>
<li>LeCaRD [24] 是中国法律体系下的第一个刑事案例检索数据集。LeCaRD<br>中的查询只包含事实段落，而候选文档则是整个案例。每个查询有一个包含100个候选文档的文档池。</li>
<li>CAIL2022-LCR 是由 CAIL2022 3 提供的官方测试集，其格式与 LeCaRD 相同。</li>
<li>COLIEE2020 [28] 是由 COLIEE2020 4<br>提供的官方数据集。每个查询有200个候选文档。参与者需要重新对每个查询的有限数量的案例进行排名。</li>
<li>COLIEE2021 [27] 是由 COLIEE2021 5<br>提供的官方数据集。没有候选文档池，参与者需要从整个语料库中确定相关案例，使得检索任务比<br>COLIEE2020 更加困难。我们在 LeCaRD 和 CAIL2022-LCR<br>上报告了所有模型的零样本性能，因为注释查询的数量非常有限。对于 COLIEE2020<br>和 COLIEE2021，我们直接使用两个数据集的合并训练集对基线和 SAILER<br>进行微调，并在测试集上报告最终性能。我们遵循比赛中的评估指标。对于 LeCaRD<br>和 CAIL2022-LCR，我们报告归一化折扣累积增益（NDCG）、Precision@5、Recall@5<br>和 F1 分数。对于两个 COLIEE<br>任务，我们报告平均倒数排名（MRR）、Precision@5、Recall@5 和 F1<br>分数。具体来说，我们报告 COLIEE2021 的 R@100。</li>
</ul>
<h2 id="5-2-基线模型"><a href="#5-2-基线模型" class="headerlink" title="5.2 基线模型"></a>5.2 基线模型</h2><p>、我们采用三组基线模型进行比较：传统检索模型、通用预训练模型和面向检索的预训练模型。<br>• 传统检索模型</p>
<ul>
<li>BM25 [29] 是一种基于精确词匹配的高效稀疏检索器。</li>
<li>QL [40] 是另一种基于狄利克雷平滑的代表性传统检索模型。<br>• 通用预训练模型</li>
<li>BERT [9] 是一个多层Transformer编码器，在即时检索任务中是一个强大的基线。</li>
<li>BERT_xs 6<br>是一个针对刑法的BERT，在663亿份中国刑事裁判文书上进行了预训练。</li>
<li>RoBERTa [18]<br>是BERT的增强版本，训练数据大幅增加。与BERT相比，RoBERTa只使用MLM任务进行预训练。</li>
<li>Lawformer [34] 是法律领域的第一个中文预训练语言模型，专注于处理长文档。</li>
<li>LEGAL-BERT [5]<br>是使用大量英文法律文件进行预训练的语言模型，在多个任务中取得了最先进的结果。<br>• 面向检索的预训练模型</li>
<li>Condenser [14]<br>是针对即时密集检索设计的模型。它利用跳跃连接将文本信息聚合为密集向量。</li>
<li>coCondenser [15]<br>在Condenser的基础上添加了一个无监督的语料库级对比损失，可以有效地热化向量空间。</li>
<li>SEED [21]<br>从理论上分析了自编码器结构在密集检索中的不足之处。它使用弱解码器来增强编码器的训练过程。</li>
<li>CoT-MAE [33] 设计了高效的数据构建方法，以训练不对称的编码器-解码器架构。</li>
<li>RetroMAE [19]<br>提出了增强的解码方法，使文本的重构更加困难，并在即时检索中取得了最先进的性能。</li>
</ul>
<p>对于传统模型，我们使用默认参数的 pyserini 工具包 7<br>进行处理。对于通用预训练模型，我们直接采用开源检查点来热启动模型参数。对于面向检索的预训练模型，我们使用与<br>SAILER<br>相同的法律预训练语料，并使用其论文中报告的最佳参数进行预训练。所有面向检索的预训练模型都是由<br>BERT 初始化的。</p>
<h2 id="5-3-实现细节"><a href="#5-3-实现细节" class="headerlink" title="5.3 实现细节"></a>5.3 实现细节</h2><h3 id="5-3-1-预训练流程。"><a href="#5-3-1-预训练流程。" class="headerlink" title="5.3.1 预训练流程。"></a>5.3.1 预训练流程。</h3><p>为构建中文法律案例的预训练语料库，我们从中国裁判文书网 8<br>收集了数千万份案例文档。我们将案例文档分为五个部分：程序、事实、推理、决定和尾部，使用正则表达式匹配。我们过滤了事实少于50个单词的简单案例。为了预训练英文模型，我们从美国联邦和州法院<br>9<br>收集了大量案例文档。与LEGAL-BERT不同，我们的预训练语料库只包含案例文档，不包括立法和合同。我们使用<br>Huggingface 的 chinese-bert-wwm 10&#x2F;bert-base-uncased11<br>初始化中文&#x2F;英文版本的 SAILER<br>编码器，解码器是随机初始化的变压器层。默认的掩码比率为编码器为<br>0.15，解码器为 0.45。我们使用 AdamW [20]<br>优化器进行最多10个时期的预训练，学习率为1e-5，批次大小为72，线性调度的热启动比率为0.1。对于决策解码器，在中文案例中我们掩码法律条文、指控和处罚条款，而在英文案例中掩码具有更高<br>TF-IDF [1]<br>分数的单词。英文版本的决策解码器与推理解码器保持相同的掩码比率。</p>
<h3 id="5-3-2-微调流程。"><a href="#5-3-2-微调流程。" class="headerlink" title="5.3.2 微调流程。"></a>5.3.2 微调流程。</h3><p>对于微调，在给定一个查询时，我们使用 BM25<br>从整个语料库中检索出前100个相关文档，将不相关文档视为硬负样本。我们使用<br>AdamW [20]<br>优化器进行最多20个时期的微调，学习率为5e-6，批次大小为4，线性调度的热启动比率为0.1。每个批次包含一个查询和十六个文档，这意味着正样本和硬负样本的比率为1:15。本文的所有实验均在8台NVIDIA<br>Tesla A100 GPU上进行。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2011.png" alt="Untitled"></p>
<h2 id="5-4-实验结果"><a href="#5-4-实验结果" class="headerlink" title="5.4 实验结果"></a>5.4 实验结果</h2><h3 id="5-4-1-零样本评估。"><a href="#5-4-1-零样本评估。" class="headerlink" title="5.4.1 零样本评估。"></a>5.4.1 零样本评估。</h3><p>为验证 SAILER 的有效性，我们在两个中国刑法数据集上进行了零样本实验。SAILER<br>与基线模型的性能比较如表3所示。从实验结果中得出以下观察：<br>• 在零资源情况下，BM25 和 QL 在法律案例检索任务上提供了竞争性能。<br>•<br>通用预训练模型通常表现不如传统的词汇匹配方法。缺乏特定的预训练目标，如BERT等语言模型无法准确捕获法律案例检索中的相关性概念。<br>•<br>面向检索的预训练模型通常表现优于通用预训练模型。这表明，应用面向检索的预训练目标而不是通用的自然语言处理目标对检索任务是有益的。<br>•<br>令人惊讶的是，中文RoBERTa比使用大量刑法数据训练的模型更有效。没有下一句预测（NSP）任务，RoBERTa提升了[CLS]嵌入的稳健性。这可能表明，下一句预测任务对提高PLMs的检索性能并不有帮助。<br>• 最后，我们注意到在两个数据集上 SAILER<br>在大多数指标上都取得了最佳性能。没有任何监督数据，SAILER<br>不仅明显优于其他预训练模型，而且是唯一击败传统检索方法的模型。这个观察结果表明，在没有可用的监督数据的情况下，将案例结构的知识纳入预训练过程是有效的，揭示了<br>SAILER 在此类场景中的巨大潜力。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2012.png" alt="Untitled"></p>
<h3 id="5-4-2-微调评估。"><a href="#5-4-2-微调评估。" class="headerlink" title="5.4.2 微调评估。"></a>5.4.2 微调评估。</h3><p>如表4所示，我们在训练数据上将 SAILER<br>与各种基线模型进行了比较。为了公平比较，不同的预训练模型利用相同的微调数据和相同大小的超参数。从实验结果中得出以下发现：<br>• 在微调设置下，传统检索模型（如BM25、QL）在两个数据集上仍表现良好。<br>•<br>在有标注数据的指导下，预训练模型进一步得到改进。但是，在某些方面它们仍然不如传统的检索方法，例如，在<br>COLIEE2021 的 R@100 指标上，QL 比大多数基线模型表现更好。<br>• 总体而言，SAILER 在所有基线模型上都取得了改进。SAILER<br>充分利用了法律案例的内在结构，通过上下文标记推断出专业知识。即使没有复杂的增强解码，它也能胜过<br>RetroMAE。在 COLIEE2021 上，SAILER 是唯一超越 QL 在 Recall@100<br>指标上的预训练模型，表明它能更好地区分大语料库中混淆的案例。由于测试案例数量有限，实际上之前的研究没有在<br>COLIEE 数据集上进行显著性测试。尽管 SAILER 在 COLIEE2020 数据集上相对于<br>SEED 和 RetroMAE 模型的改进不是非常显著，但 SAILER<br>仍然实现了最先进的指标值。一般来说，参数大小相同的PLMs在微调后表现接近。因此，性能上的不显著改进也可以表明我们方法的有效性。</p>
<h2 id="5-5-消融研究"><a href="#5-5-消融研究" class="headerlink" title="5.5 消融研究"></a>5.5 消融研究</h2><p>为了更好地阐明模型设计和预训练任务的有效性，我们在 LeCaRD<br>数据集上进行了消融研究，采用零样本设置。表5展示了不同预训练目标的影响。SAILER_share<br>是 SAILER<br>的一个变体，其中推理和决策部分由共享的解码器重构。我们可以观察到，共享单个解码器导致了轻微的性能下降，这证实了我们多解码器架构的有效性。此外，我们分别移除了推理解码器和决策解码器，两者都导致了显著的性能下降。与移除决策解码器相比，移除推理解码器导致的性能下降较少。一个可能的原因是我们在推理解码器中使用的随机屏蔽不能有效地屏蔽所有关键法律要素，因此为<br>SAILER<br>提供了有限的指导。如何确定推理部分中关键法律要素的位置是我们未来工作的方向之一。最后，当移除所有解码器后，性能急剧下降。以上实验证实了我们预训练目标的有效性。</p>
<h2 id="5-6-超参数分析"><a href="#5-6-超参数分析" class="headerlink" title="5.6 超参数分析"></a>5.6 超参数分析</h2><p>5.6.1 屏蔽率的影响<br>在这一部分，我们探讨了不同屏蔽率对 SAILER 的影响。我们在 LeCaRD<br>数据集上进行了实验，其中编码器的屏蔽率从0变化到0.30，解码器的屏蔽率从0.15增加到0.60。结果如表6所示。有几个有趣的发现。<br>（1）解码器屏蔽率的增加将使解码过程更加困难，模型性能在一定程度上会提高。当解码器屏蔽率高于0.45时，这种增长会变得不稳定。我们认为过度困难的解码可能对模型的学习是不利的。<br>（2）适当的编码器屏蔽率有助于提高性能。然而，当编码器屏蔽率过高时，SAILER<br>的性能会略微降低。这是因为过大的屏蔽率将阻止生成高质量的句子嵌入，考虑到在这种情况下大部分有用信息都将被丢弃。<br>（3）总的来说，SAILER<br>在广泛的屏蔽率范围内表现良好，显示出它的稳健性。当编码器屏蔽率为0.15，解码器屏蔽率为0.45时，SAILER<br>实现了最佳性能。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2013.png" alt="Untitled"></p>
<h3 id="5-6-2-解码器层数的影响。"><a href="#5-6-2-解码器层数的影响。" class="headerlink" title="5.6.2 解码器层数的影响。"></a>5.6.2 解码器层数的影响。</h3><p>我们进一步探索解码器层数对性能的影响。我们在实验中保持了推理解码器和决策解码器的层数相同。实验结果如表7所示。随着解码器层数的增加，SAILER的性能下降，这与<br>SEED [21] 的发现相似。总体而言，SAILER在解码器层数方面的性能非常稳健。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2014.png" alt="Untitled"></p>
<h2 id="5-7-案例研究。"><a href="#5-7-案例研究。" class="headerlink" title="5.7 案例研究。"></a>5.7 案例研究。</h2><p>为了进一步分析 SAILER<br>的检索机制，我们在图4中可视化了单词的注意力权重，单词越暗表示其获得的注意力权重越高。为了公平比较，我们选择了与<br>SAILER 使用相同解码机制来重构原始文本的 SEED 进行案例研究。SEED 和 SAILER<br>的注意力分布存在许多差异。可以观察到，SEED 最关注 cofetol cough<br>syrup（一种药物的名称）、Guangzhou（城市名称）、Chen（人名）等。而 SAILER<br>更关注影响最终判决的词语，比如 sold、drug、allowed<br>等。值得一提的是，“allow”（允许）是这个案件的关键词，因为为吸毒者提供场所是一个典型的指控，意味着被告允许他人在自己的场所吸毒。我们可以观察到在<br>SAILER 中，“allow” 被强调了。这表明 SAILER<br>融入了法律知识，并更加关注关键的法律要素。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2015.png" alt="Untitled"></p>
<h2 id="5-8-视觉分析。"><a href="#5-8-视觉分析。" class="headerlink" title="5.8 视觉分析。"></a>5.8 视觉分析。</h2><p>为了进一步探索 SAILER 的区分能力，我们使用 t-SNE<br>对法律案件的向量分布进行可视化。具体而言，我们选择了六种易混淆的指控，包括故意伤害、挑衅、聚众斗殴、盗窃、抢劫和诈骗。对于每一项指控，我们从预训练语料库中随机选取了一定数量的法律案例。我们在零样本情况下利用现成的预训练模型生成了法律案件的向量。从图5可以看出，SAILER<br>具有强大的区分能力。对于中文 BERT，它总是混淆不同指控的案件。虽然中文<br>RoBERTa<br>能够区分盗窃、抢劫和诈骗这三种指控，但它混淆了故意伤害、挑衅和聚众斗殴。通过重构原始文本，SEED<br>学到了更多信息，并生成了均匀分布的向量。然而，相似指控的边界太接近，这对于法律案件检索是不利的。相比之下，SAILER<br>能够更准确地区分不同指控的向量，而且没有任何监督数据，表明它通过我们的预训练目标学习了丰富的法律知识。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2016.png" alt="Untitled"></p>
<h1 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h1><p>本文提出了<br>SAILER，这是一个面向法律案件检索的新型结构感知的预训练语言模型。SAILER<br>的关键思想是充分利用法律案件文档的结构关系进行预训练。通过重构关键法律要素和判决结果，SAILER<br>生成了更好的法律案件表示，并具有更强的区分能力。通过在四个基准法律数据集上进行大量实验，SAILER<br>在低资源和全资源设置下相对于基线模型取得了显著的改进。在未来，我们希望探索将更多专家知识，如法律知识图谱和法律条文，纳入预训练语言模型中，以实现更好的法律案件检索效果。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER%20Structure-aware%20%20de964d359bdc4f19bfbca3c139bef7ab/Untitled%2017.png" alt="Untitled"></p>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>License</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">Older</div><a href="/2024/04/19/CaseEncoder-%E7%94%A8%E4%BA%8E%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E7%BC%96%E7%A0%81%E7%9A%84%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/">CaseEncoder_用于法律案例编码的知识增强预训练模型</a></div></section></div>






<footer class="page-footer footnote"><hr><div class="text"><p>本站由 <a href="/">Hannah</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.27.0">Stellar 1.27.0</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">On This Page</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#SAILER%EF%BC%9A%E9%9D%A2%E5%90%91%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2%E7%9A%84%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BSAILER-Structure-aware"><span class="toc-text">SAILER：面向法律案例检索的结构感知预训练语言模型SAILER: Structure-aware</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text">2 相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E9%92%88%E5%AF%B9%E5%AF%86%E9%9B%86%E6%A3%80%E7%B4%A2%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-text">2.1 针对密集检索的预训练语言模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E6%B3%95%E5%BE%8B%E6%A1%88%E4%BE%8B%E6%A3%80%E7%B4%A2"><span class="toc-text">2.2 法律案例检索</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E8%83%8C%E6%99%AF%E5%92%8C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-text">3 背景和基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E9%97%AE%E9%A2%98%E9%98%90%E8%BF%B0"><span class="toc-text">3.1 问题阐述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E5%88%9D%E6%AD%A5%E7%9F%A5%E8%AF%86"><span class="toc-text">3.2 初步知识</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E6%96%B9%E6%B3%95"><span class="toc-text">4 方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E4%BA%8B%E5%AE%9E%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-text">4.1 事实编码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E6%8E%A8%E7%90%86%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-text">4.2 推理解码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E5%86%B3%E5%AE%9A%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-text">4.3 决定解码器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-%E5%AD%A6%E4%B9%A0"><span class="toc-text">4.4 学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-%E5%AE%9E%E9%AA%8C"><span class="toc-text">5 实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E6%8C%87%E6%A0%87"><span class="toc-text">5.1 数据集和指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E5%9F%BA%E7%BA%BF%E6%A8%A1%E5%9E%8B"><span class="toc-text">5.2 基线模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82"><span class="toc-text">5.3 实现细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E3%80%82"><span class="toc-text">5.3.1 预训练流程。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-%E5%BE%AE%E8%B0%83%E6%B5%81%E7%A8%8B%E3%80%82"><span class="toc-text">5.3.2 微调流程。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">5.4 实验结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-1-%E9%9B%B6%E6%A0%B7%E6%9C%AC%E8%AF%84%E4%BC%B0%E3%80%82"><span class="toc-text">5.4.1 零样本评估。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-2-%E5%BE%AE%E8%B0%83%E8%AF%84%E4%BC%B0%E3%80%82"><span class="toc-text">5.4.2 微调评估。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6"><span class="toc-text">5.5 消融研究</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-6-%E8%B6%85%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90"><span class="toc-text">5.6 超参数分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-2-%E8%A7%A3%E7%A0%81%E5%99%A8%E5%B1%82%E6%95%B0%E7%9A%84%E5%BD%B1%E5%93%8D%E3%80%82"><span class="toc-text">5.6.2 解码器层数的影响。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-7-%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6%E3%80%82"><span class="toc-text">5.7 案例研究。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-8-%E8%A7%86%E8%A7%89%E5%88%86%E6%9E%90%E3%80%82"><span class="toc-text">5.8 视觉分析。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-%E7%BB%93%E8%AE%BA"><span class="toc-text">6 结论</span></a></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>Scroll to Top</span></a><a class="buttom" onclick="util.scrollComment()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M10.46 1.25h3.08c1.603 0 2.86 0 3.864.095c1.023.098 1.861.3 2.6.752a5.75 5.75 0 0 1 1.899 1.899c.452.738.654 1.577.752 2.6c.095 1.004.095 2.261.095 3.865v1.067c0 1.141 0 2.036-.05 2.759c-.05.735-.153 1.347-.388 1.913a5.75 5.75 0 0 1-3.112 3.112c-.805.334-1.721.408-2.977.43a10.81 10.81 0 0 0-.929.036c-.198.022-.275.054-.32.08c-.047.028-.112.078-.224.232c-.121.166-.258.396-.476.764l-.542.916c-.773 1.307-2.69 1.307-3.464 0l-.542-.916a10.605 10.605 0 0 0-.476-.764c-.112-.154-.177-.204-.224-.232c-.045-.026-.122-.058-.32-.08c-.212-.023-.49-.03-.93-.037c-1.255-.021-2.171-.095-2.976-.429A5.75 5.75 0 0 1 1.688 16.2c-.235-.566-.338-1.178-.389-1.913c-.049-.723-.049-1.618-.049-2.76v-1.066c0-1.604 0-2.86.095-3.865c.098-1.023.3-1.862.752-2.6a5.75 5.75 0 0 1 1.899-1.899c.738-.452 1.577-.654 2.6-.752C7.6 1.25 8.857 1.25 10.461 1.25M6.739 2.839c-.914.087-1.495.253-1.959.537A4.25 4.25 0 0 0 3.376 4.78c-.284.464-.45 1.045-.537 1.96c-.088.924-.089 2.11-.089 3.761v1c0 1.175 0 2.019.046 2.685c.045.659.131 1.089.278 1.441a4.25 4.25 0 0 0 2.3 2.3c.515.214 1.173.294 2.429.316h.031c.398.007.747.013 1.037.045c.311.035.616.104.909.274c.29.17.5.395.682.645c.169.232.342.525.538.856l.559.944a.52.52 0 0 0 .882 0l.559-.944c.196-.331.37-.624.538-.856c.182-.25.392-.476.682-.645c.293-.17.598-.24.909-.274c.29-.032.639-.038 1.037-.045h.032c1.255-.022 1.913-.102 2.428-.316a4.25 4.25 0 0 0 2.3-2.3c.147-.352.233-.782.278-1.441c.046-.666.046-1.51.046-2.685v-1c0-1.651 0-2.837-.089-3.762c-.087-.914-.253-1.495-.537-1.959a4.25 4.25 0 0 0-1.403-1.403c-.464-.284-1.045-.45-1.96-.537c-.924-.088-2.11-.089-3.761-.089h-3c-1.651 0-2.837 0-3.762.089" clip-rule="evenodd"/><path fill="currentColor" d="M9 11a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0"/></svg><span>Join Discussion</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `Just`,
      min: `minutes ago`,
      hour: `hours ago`,
      day: `days ago`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.27.0" async></script>

<!-- optional -->



<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/flying-pages/2.1.2/flying-pages.min.js"></script><script defer src="https://cdn.bootcdn.net/ajax/libs/vanilla-lazyload/17.8.4/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });
</script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.min.css`,
    js: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.umd.min.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || null
        }
      });
    })
  }
</script><script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
